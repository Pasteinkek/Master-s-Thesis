\section{Conditional convergence in the multiphase case}

Let us now turn to the much more interesting and more challenging case where we consider systems of the Allen--Cahn equation (\ref{allen_cahn_eq}), or in other words, we want to consider the case where $ u_{\varepsilon } $ maps to $ \mathbb{ R }^{ N } $ and therefore our potential $ W $ is a map from $ \mathbb{ R }^{ N } $ to $ [ 0 , \infty ) $. The for us most relevant case is when $ W $ has exactly $ P = N + 1 $ zeros given by $ \alpha_{ 1 } , \dotsc, \alpha_{ P } $, but it is no limitation for us to allow more general amount of zeros.

Let us also fix some notation for this section. For a function $ u = \sum_{ i = 1 }^{ P } \mathds{ 1 }_{ \Omega_{ i } } \alpha_{ i } $ and the corresponding interfaces $ \Sigma_{ i , j } \coloneqq \partial_{ \ast } \Omega_{ i } \cap \partial_{ \ast } \Omega_{ j } $, we define for a given testfunction $ \varphi \in \cont^{ \infty } ( \flattorus ) $ the localized energies by
\begin{align}
	\label{localized__epsilon_energy_multiphase}
	\energy_{ \varepsilon } ( u_{ \varepsilon } ; \varphi )
	& \coloneqq
	\int
		\varphi \left(
			\frac{ 1 }{ \varepsilon }
			W ( u_{ \varepsilon } ) 
			+
			\frac{ \varepsilon }{ 2 }
			\abs{ \nabla u_{ \varepsilon } }^{ 2 }
		\right)
	\dd{ x }
	\shortintertext{and}
	\label{localized_energy_multiphase}
	\energy ( u ; \varphi )
	& \coloneqq
	\sum_{ i < j }
		\sigma_{ i , j }
		\int_{ \Sigma_{ i , j } }
			\varphi
		\dd{\hm^{ d - 1 }}.
\end{align}

\subsection{Convergence to a moving partition}

One of the many difficulties in the vectorial case is that that there is no easy choice of a primitive for $ \sqrt{ 2 W ( u ) } $ compared to the scalar case. We there saw for example through the Modica-Mortula trick (\ref{modica_mortula_trick}) that this provided a very powerful tool for us, and comparing the composition $ \phi \circ u_{ \varepsilon } $ to $ u_{ \varepsilon } $ was quite simple since the map $ \phi $ was invertible as a consequence of the non-negativity of $ W $.

As a suitable replacement, we shall consider the \emph{geodesic distance} defined as 
\begin{equation*}
		\geodesic_distance ( u, v )
		\coloneqq
		\inf
		\left\{
		\int_{ 0 }^{ 1 }
		\sqrt{ 2 W ( \gamma ) }
		\abs{ \dot{ \gamma }  }
		\dd{t}
		\,
		\colon
		\, \gamma \in \mathrm{ C }^{ 1 } \left( [0, 1 ] ; \mathbb{ R }^{ N } \right) \text{ with } \gamma( 0 ) = u,\, \gamma( 1 )= v 
		\right\}.
\end{equation*}
This indeed defines a metric on $ \mathbb{ R }^{ N } $: If $ \geodesic_distance ( v, w ) = 0 $, then by the continuity of $ W $ and since it only has a discrete set of zeros, we may deduce that $ v = w $. Symmetry can be seen by reversing a given path between two points and the triangle inequality follows from concatenation of two paths and rescaling.
Note moreover that by an approximation argument (for example through splines), we may also take paths $ \gamma $ which are piecewise continuously differentiable which makes constructions of paths easier.

The \emph{geodesic distances} generated by $ W $  are defined as
\begin{equation*}
	\sigma_{ i , j } 
	\coloneqq
	\geodesic_distance ( \alpha_{ i } , \alpha_{ j } )
\end{equation*}
and as a consequence of $ \geodesic_distance $ being a metric satisfy
\begin{equation*}
	\sigma_{ i , k } \leq \sigma_{ i , j } + \sigma_{ j , k },
\end{equation*}
$ \sigma_{ i , j } = 0 $ if and only if $ i $ is equal to $ j $ and $ \sigma_{ i , j } = \sigma_{ j, i } $.

Our replacement for the primitive $ \phi $ is now given for $ 1 \leq i \leq P $ by the function
\begin{equation*}
	\phi_{ i } ( u ) 
	\coloneqq
	\geodesic_distance ( \alpha_{ i } , u ).
\end{equation*}
Our first obstacle is the regularity of the function $ \psi_{ \varepsilon }^{ i } \coloneqq \phi_{ i } \circ u_{ \varepsilon } $. A priori we only know that $ \phi_{ i } $ is locally Lipschitz continuous on $ \mathbb{ R }^{ N } $ and thus differentiable almost everywhere. If $ N = 1 $, then this would already suffice to deduce that $ \psi_{ \varepsilon  }^{ i } $ is weakly differentiable, but in higher dimensions, $ u $ could for example move along a hyperplane where $ \phi_{ i } $ could in theory be nowhere differentiable since it is a Lebesgue nullset. This can however be salvaged through the following chain rule for distributional derivatives by Ambrosio and Maso \cite[Cor.~3.2]{ambrosio_maso_chain_rule}.

\begin{theorem}
	\label{chain_rule_for_distributional_derivatives}
	Let $ \Omega \subseteq \mathbb{ R }^{ d } $ be an open set, $ p \in [0, \infty ] $, $ u \in \wkp^{ 1, p } ( \Omega ; \mathbb{ R }^{ N } ) $ and let $ f \colon \mathbb{ R }^{ N } \to \mathbb{ R }^{ k } $ be a Lipschitz continuous function such that $ f ( 0 ) = 0 $. Then $ v \coloneqq f \circ u \in \wkp^{ 1, p } \left( \Omega , \mathbb{ R }^{ k } \right) $. Furthermore for almost every $ x \in \Omega $ the restriction of $ f $ to the affine space 
	\begin{equation*}
		T_{ x }^{ u }
		\coloneqq
		\left\{
			y \in \mathbb{ R }^{ N }
			\, \colon \,
			y = u ( x ) + \diff u ( x ) z 
			\text{ for }
			z \in \mathbb{ R }^{ d }
		\right\}
		=
		u( x ) 
		+
		\dot{ T }_{ x }^{ u }
	\end{equation*}
	is differentiable at $ u( x ) $ and
	\begin{equation*}
		\diff v 
		=
		\diff \left(
			f |_{ T_{ x }^{ u } }
		\right) ( u ) 
		\diff u 
	\end{equation*}
	holds almost everywhere in $ \Omega $.
\end{theorem}
\begin{remark}
	The matrix 	
	$\diff \left(
	f |_{ T_{ x }^{ u } }
	\right) ( u ) 
	$
	can be interpreted as some matrix in $ \mathbb{ R }^{ k \times n } $ which acts on $ v \in \dot{ T }_{ x }^{ u } $ by
	\begin{equation*}
		\diff \left(
		f |_{ T_{ x }^{ u } }
		\right) ( u ( x ) ) 
		[ v ]
		=
		\lim_{ h \to 0 }
			\frac{ f ( u ( x ) + h v ) - f ( u ( x ) ) }{ h }.
	\end{equation*}
	Thus we may choose a suitable representative since the product $ \diff \left(
	f |_{ T_{ x }^{ u } }
	\right) ( u )  
	\diff u $
	will not change by definition of $ \dot{ T }_{ x }^{ u } $.
	
	Moreover the assumption $ f( 0 ) = 0 $ can be left out on bounded domains by simply subtracting the constant $ f( 0 ) $.
\end{remark}

We are not in the position to prove the following regularity result.

\begin{lemma}
	\label{chain_rule_lemma}
	Let $ u \in \cont \left( [ 0 , T ] ; \lp^{ 2 } ( \flattorus ; \mathbb{ R }^{ N } ) \right) $ with
	\begin{equation*}
		\esssup_{ 0 \leq t \leq T }
			\energy_{ \varepsilon } ( u ) 
		+
		\int_{ 0 }^{ T }
			\int
				\varepsilon 
				\abs{ \partial_{ t } u }^{ 2 }
			\dd{ x }
		\dd{ t }
		< 
		\infty 
	\end{equation*}
	for some $ \varepsilon > 0 $. Then for all $ 1 \leq i \leq P $ there exists a map
	\begin{equation*}
		\partial_{ u } \phi_{ i } ( u )
		\colon
		[ 0 , T ] \times \flattorus
		\to 
		\mathrm{Lin} \left( \mathbb{ R }^{ N } , \mathbb{ R } \right)
	\end{equation*}
	such that the chain rule is valid with the pair $ \partial_{ u } \phi_{ i } ( u ) $ and 
	$ ( \partial_{ t }, \nabla ) u $:
	
	For almost every $ ( t , x ) \in [ 0 , T ] \times \flattorus $ we have
	\begin{equation*}
		\nabla ( \phi_{ i } \circ u )
		=
		\partial_{ u } \phi_{ i } ( u ) \nabla u 
		\quad
		\text{and}
		\quad
		\partial_{ t } ( \phi_{ i } \circ u )
		=
		\partial_{ u } \phi_{ i } ( u ) 
		\partial_{ t } u.
	\end{equation*}
	Furthermore we can control the modulus of $ \partial_{ u } \phi_{ i } ( u ) $ almost everywhere in time and space via the estimate
	\begin{equation}
		\label{estimate_on_partial_u_phi}
		\abs{ \partial_{ u } \phi_{ i } ( u ) }
		\leq
		\sqrt{ 2 W ( u ) }.
	\end{equation}
	Additionally we have $ \phi_{ i } \circ u \in \lp^{ \infty } \left( [ 0 , T ] ; \wkp^{ 1, 1 } ( \flattorus ) \right) \cap \wkp^{ 1, 1 } ( [ 0 , T ] \times \flattorus ) $ with the estimates
	\begin{align}
		\label{l1_estimate_for_phi_composed_u}
		\esssup_{ 0 \leq t \leq T }
			\int
				\abs{ \phi_{ i } \circ u }
			\dd{ x }
		& \lesssim
		1 + \esssup_{ 0 \leq t \leq T } \varepsilon \energy_{ \varepsilon } ( u ) ,
		\\
		\label{l1_estimate_on_nabla_phi_composed_u}
		\esssup_{ 0 \leq t \leq T }
			\int
				\abs{ \nabla ( \phi_{ i } \circ u ) }
			\dd{ x }
		& \leq
		\esssup_{ 0 \leq t \leq T }
			\energy_{ \varepsilon } ( u )
		\shortintertext{and}
		\label{l1_estimate_on_partial_t_phi_composed_u}
		\int_{ 0 }^{ T }
			\int
				\abs{ \partial_{ t } ( \phi_{ i } \circ u ) }
			\dd{ x }
		\dd{ t }
		& \leq
		T
		\esssup_{ 0 \leq t \leq T }
			\energy_{ \varepsilon } ( u )
		+
		\int_{ 0 }^{ T }
			\int
				\varepsilon
				\abs{ \partial_{ t } u }^{ 2 }
			\dd{ x }
		\dd{ t }.
	\end{align}
\end{lemma}

\begin{proof}
	Since \Cref{chain_rule_for_distributional_derivatives} requires Lipschitz continuity of $ \phi_{ i } $, but we only have local Lipschitz continuity, let us first assume that $ u $ is bounded in space and time. Then we may modify $ \phi_{ i } $ outside of a compact set such that it is (globally) Lipschitz continuous and does not change on the image of $ u $.
	
	Since we have via the energy estimate that $ u \in \wkp^{ 1 , 2 } ( [ 0 , T ] \times \flattorus ; \mathbb{ R }^{ N } ) $, we obtain by the distributional chain rule \Cref{chain_rule_for_distributional_derivatives} that $ \psi = \phi_{ i } \circ u \in \wkp^{ 1 , 2 } ( [ 0, T ] \times \flattorus ) $.
	
	Let $ \Pi ( t , x ) $ denote the orthogonal projection of $ \mathbb{ R }^{ N } $ onto $ \dot{ T }_{ x, t }^{ u } $ and define 
	\begin{equation*}
		\partial_{ u } \phi_{ i } ( u ) ( t, x ) [ v ]
		\coloneqq
		\diff ( \phi_{ i } |_{ T_{ t , x }^{ u } } ) ( u ( t , x ) ) [ \Pi ( t , x ) v ].
	\end{equation*}
	This defines a unique row vector and thus we can now proceed to prove inequality (\ref{estimate_on_partial_u_phi}).
	Let $ v \in \dot{ T }_{ t, x }^{ u } $, a real number $ h \in \mathbb{ R } \setminus \{ 0 \} $ and $ \gamma \colon [ 0 , 1 ] \to \mathbb{ R }^{ N } $ be a path connecting $ \alpha_{ i } $ and $ u $. Then we define the new path $ \tilde{ \gamma } \colon [ 0 , 1 ] \to \mathbb{ R }^{ N } $ by 
	\begin{equation*}
		\tilde{ \gamma } ( t ) =
		\begin{cases}
			\gamma ( \frac{ t }{ 2 } ) 
			& , t \leq \frac{ 1 }{ 2 }
			\\
			u + 
			\left( t - \frac{ 1 }{ 2 } \right)
			2 h v
			&, t \geq \frac{ 1 }{ 2 }.
		\end{cases}
	\end{equation*}
	We observe that $ \tilde{ \gamma } $ is a piecewise continuously differentiable path connecting $ \alpha_{i } $ and $ u + h v $, thus we can estimate by a substitution that
	\begin{align*}
		& \geodesic_distance ( \alpha_{ i } , u + hv )
		-
		\int_{ 0 }^{ 1 }
			\sqrt{
				2 W ( \gamma ( t ) ) }
			\abs{ \gamma ' ( t ) }
		\dd{ t }
		\\
		\leq {} &
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( \tilde{ \gamma } ( t ) ) } 
			\abs{ \tilde{ \gamma } ' ( t ) }
		\dd{ t }
		-
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( \gamma ( t ) ) } 
			\abs{ \gamma ' ( t ) }
		\dd{ t }
		\\
		={} &
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( u + t h v ) }
			\abs{ h v }
		\dd{ t }.
	\end{align*}
	Taking the infimum over all $ \cont^{ 1 } $-paths connecting $ \alpha_{ i } $ and $ u $ yields 
	\begin{equation*}
		\geodesic_distance ( \alpha_{ i } , u + h v )
		- 
		\geodesic_distance ( \alpha_{ i } , u )
		\leq
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( u + t h v ) }
			\abs{ h v }
		\dd{ t }.
	\end{equation*}
	Using a similar strategy but with a reversed path, we also obtain the inequality
	\begin{equation*}
		\geodesic_distance ( \alpha_{ i } , u ) 
		-
		\geodesic_distance ( \alpha_{ i } , u + h v )
		\leq
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( u + t h v ) }
			\abs{ h v }
		\dd{ t },
	\end{equation*}
	thus we obtain by the dominated convergence theorem
	\begin{equation*}
		\limsup_{ h \to 0 }
			\abs{
			\frac{ \phi ( u + h v ) - \phi ( u ) }{ h }
			}
		\leq
		\limsup_{ h \to 0 }
			\int_{ 0 }^{ 1 }
				\sqrt{ 2 W ( u + t h v ) }
				\abs{ v }
			\dd{ t }
		= 
		\sqrt{ 2 W ( u ) } \abs{ v },
	\end{equation*}
	which yields
	\begin{equation*}
		\abs{ \diff \phi_{ i } |_{ T_{ t, x }^{ u } } ( u ) [ v ] }
		\leq
		\sqrt{ 2 W ( u ) } \abs{ v }
	\end{equation*}
	and thus gives us the desired inequality (\ref{estimate_on_partial_u_phi}) since $ \abs{ \Pi ( v ) } \leq \abs{ v } $.
	
	Now let us consider the general case and denote by $ u_{ M } $ the truncation of $ u $ defined by
	\begin{equation*}
		u_{ M }^{ j } 
		\coloneqq
		\begin{cases}
			u &, \text{ if} \abs{ u^{ j } } \leq M 
			\\
			M \frac{ u^{ j } }{ \abs{ u_{ j } } }
			&, \text{ else}.
		\end{cases}
	\end{equation*}
	Then we still have $ u_{ M } \in \wkp^{ 1, 2 } ( [ 0 , T ] \times \flattorus ) $ and obtain by the previous step that $ \phi_{ i } \circ u_{ M } \in \wkp^{ 1, 2 } ( [ 0 , T ] \times \flattorus ) $ and that for almost every $ ( t, x ) \in [ 0 , T ] \times \flattorus $, the function $ \phi_{ i } $ is differentiable on $ T_{ t, x }^{ u_{ M } } $. Moreover if $ ( t, x ) \in u^{ - 1 } ( [ - M , M ]^{ N } ) $, then we obtain $ T_{ t, x }^{ u_{ M } } = T_{ t, x }^{ u } $.
	Next we we want to show that $ \phi_{ i } \circ u_{ M } $ converges to $ \phi_{ i } \circ u $ in a suitable sense. First we recognize that $ \phi_{ i } \circ u_{ M } $ converges to $ \phi_{ i } \circ u $ pointwise almost everywhere. Moreover we find a majorant since
	\begin{align}
		\notag
		\phi_{ i } ( v ) 
		&
		\leq
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( \alpha_{ i } + s ( v - \alpha_{ i } ) ) }
			\abs{ v - \alpha_{i } }
		\dd{ s }
		\leq
		\norm{ \sqrt{ 2 W } }_{ \lp^{ \infty } [ v, \alpha_{ i } ] }
		\abs{ v - \alpha_{ i } }
		\\
		\label{majorant_for_phi}
		& \lesssim
		1 + \abs{ v }^{ 1 + p/2 },
	\end{align}
	thus we have $ \phi_{ i } \circ u_{ M } \lesssim 1 + \abs{ u }^{ p } $, which is in integrable majorant. Therefore the dominated convergence theorem yields that $ \phi_{ i } \circ u_{ M } $ converges to $ \phi_{ i } \circ u $ in $ \lp^{ 1 } ( [ 0 , T ] \times \flattorus ) $.
	Moreover estimate (\ref{majorant_for_phi}) together with the $ p $-growth of $ W $ (\ref{polynomial_growth}) already yield the desired $ \lp^{ 1 } $-estimate (\ref{l1_estimate_for_phi_composed_u}).
	
	Furthermore we recognize that on the set $ \{ u_{M } = u \} $, we already have
	\begin{equation*}
		( \partial_{ t } , \nabla ) u_{ M }
		=
		( \partial_{ t } , \nabla ) u
	\end{equation*}
	and the sets $ \{ u_{ M } = u \} $ are non-decreasing, thus
	\begin{equation*}
		\lim_{ M \to \infty }
		\abs{
			\left\{
				u_{ M } \neq u, ( \partial_{ t } , \nabla ) u_{ M } \neq ( \partial_{ t }, \nabla ) u 
			\right\}
		}
		=
		0.
	\end{equation*}
	Moreover we have that for almost every $ ( t, x ) $, the derivative $ \partial_{ u } \phi_{ i } ( u_{ M } ( t , x ) ) $ eventually becomes stationary. We denote its almost everywhere pointwise limit by $ \partial_{ u } \phi_{ i } ( u ) $ and it satisfies almost everywhere
	\begin{equation*}
		\abs{
			\partial_{ u } \phi_{ i } ( u ) 
		}
		\leq
		\sqrt{ 2 W ( u ) }.
	\end{equation*}
	In order to show that $ \phi_{ i } \circ u $ is weakly differentiable with derivative 
	\begin{equation*}
		( \partial_{ t } , \nabla ) \phi_{ i } \circ u
		=
		\partial_{ u } \phi_{ i } ( u ) ( \partial_{ t } u, \nabla u ),
	\end{equation*}
	we compute for a testfunction $ \varphi $ that by the $ \lp^{ 1 } $-convergence, we have
	\begin{align*}
		\int_{ 0 }^{ T }
		\int
			\phi_{ i } \circ u
			( \partial_{ t } , \nabla ) \varphi
		\dd{ x}
		\dd{ t }
		&
		=
		\lim_{ M \to \infty }
			\int_{0 }^{ T }
				\int
					\phi_{ i } \circ u_{ M }
					( \partial_{ t } , \nabla ) u_{ M }
					\varphi
				\dd{ x }
			\dd{ t }
		\\
		& =
		- \lim_{ M \to \infty }
			\int
				\partial_{ u } \phi_{ i } ( u_{ M } )
				( \partial_{ t } , \nabla ) u_{ M }
				\varphi
			\dd{ x }
		\dd{ t }
		\\
		& =
		- \lim_{ M \to \infty }
			\int_{ \abs{ u } \leq M }
				\partial_{ u } \phi_{ i } ( u ) 
				( \partial_{ t } , \nabla ) u
				\varphi
			\dd{ ( t, x ) }
		\\
		& =
		\int_{ 0 }^{ T }
			\int
				\partial_{ u } \phi_{ i } ( u ) 
				( \partial_{ t } , \nabla ) u
				\varphi
			\dd{ x }
		\dd{ t }.
	\end{align*}
	The last inequality is due to the dominated convergence theorem with majorant $ \abs{ \varphi } \sqrt{ 2 W ( u ) } \abs{ ( \partial_{ t } , \nabla ) u } $.
	It remains to prove the estimates (\ref{l1_estimate_on_nabla_phi_composed_u}) and (\ref{l1_estimate_on_partial_t_phi_composed_u}). These follow from applications of Young's inequality
	\begin{align*}
		\esssup_{ 0 \leq t \leq T }
			\int
				\abs{ \nabla ( \phi_{ i } \circ u ) }
		& =
		\esssup_{ 0 \leq t \leq T }
			\int
				\abs{ \partial_{ u } \phi_{ i } ( u ) \nabla u }
			\dd{ x }
		\\
		& \leq
		\esssup_{ 0 \leq t \leq T }
			\int
				\sqrt{ 2 W ( u ) }
				\abs{ \nabla u }
			\dd{ x }
		\\
		& \leq
		\sup_{ 0 \leq t \leq T }
			\energy_{ \varepsilon } ( u_{ \varepsilon } )
		\shortintertext{and}
		\int_{ 0 }^{ T }
			\int
				\abs{ \partial_{ t } ( \phi_{ i } \circ u ) }
			\dd{ x }
		\dd{ t }
		& \leq
		\int_{ 0 }^{ T }
			\int
				\frac{ 1 }{ \sqrt{ \varepsilon } }
				\sqrt{ 2 W ( u ) }
				\sqrt{ \varepsilon }
				\abs{ \partial_{ t } u }
			\dd{ x }
		\dd{ t }
		\\
		& \leq
		\int_{ 0 }^{ T }
			\int
				\frac{ 1 }{ \varepsilon}
				W ( u_{ \varepsilon } )
				+
				\frac{\varepsilon}{ 2 }
				\abs{ \partial_{  t } u }^{ 2 }
			\dd{ x }
		\dd{ t },
	\end{align*}
	which finishes our proof.
\end{proof}

With this powerful tool on our hands, we are in the position to prove a similar result to \Cref{initial_convergence_result} for the multiphase case.

\begin{proposition}
	\label{initial_convergence_result_multiphase}
	Given initial data $ u_{ \varepsilon }^{ 0 } = \sum_{ i = 1 }^{ P } \chi_{ i }^{ 0 } \alpha_{ i } $ whose energies satisfy
	\begin{equation*}
		\energy_{ \varepsilon } ( u_{ \varepsilon }^{ 0 } ) 
		\to 
		\energy ( u^{ 0 } ) 
		\eqqcolon
		E_{ 0 }
		< 
		\infty,
	\end{equation*}
	there exists for any sequence $ \varepsilon $ some non-relabelled subsequence such that the solutions of the Allen--Cahn equation (\ref{allen_cahn_eq}) with initial condition $ u_{ \varepsilon }^{ 0 } $ converge in $ \lp^{ 1 } \left( ( 0 , T ) \times \flattorus ; \mathbb{ R }^{ N } \right) $ to some $ u = \sum_{ i = 1 }^{ P } \chi_{ i } \alpha_{ i } $ with a partition $ \chi \in \bv \left( ( 0 , T ) \times \flattorus ; \{ 0 , 1 \}^{ P } \right) $.
	Furthermore we have
	\begin{equation}
		\label{energy_estimate_for_limit_u}
		\esssup_{ 0 \leq t \leq T }
			\energy ( u ) 
		\leq
		\energy_{ 0 }
	\end{equation}
	and for all $ 1 \leq i \leq P $ the compositions $ \phi_{ i } \circ u_{ \varepsilon } $ are uniformly bounded in $ \bv ( ( 0 , T ) \times \flattorus ) $ and converge to $ \phi_{ i } \circ u $ in $ \lp^{ 1 } ( ( 0 , T ) \times \flattorus $. 
\end{proposition}

\begin{remark}
	The proof is quite similar to the proof of \Cref{initial_convergence_result}, but we have to work more in order to obtain the desired convergence to $ u $.
\end{remark}

\begin{proof}
	By \Cref{existence_of_ac_solution} the solution $ u_{ \varepsilon } $ of (\ref{allen_cahn_eq}) satisfies the assumptions of \Cref{chain_rule_lemma}.
	Thus $ \psi_{ i }^{ \varepsilon } \coloneqq \varphi_{ i } \circ u_{ \varepsilon } $ is uniformly bounded in $ \bv \left( ( 0 , T ) \times \flattorus \right) $ as $ \varepsilon $ tends to zero for all $ 1 \leq i \leq P $ and thus we find a non-relabelled subsequence and $ v_{ i } \in \bv \left( ( 0 , T ) \times \flattorus \right) $ such that $ \psi_{ i }^{ \varepsilon } $ converges to $ v_{ i } $ in $ \lp^{ 1 } \left( ( 0 , T ) \times \flattorus \right) $ and pointwise almost everywhere. 
	
	We now want to show that we can write $ v_{ i } = \phi_{ i } \circ u $ for $ u = \sum \chi_{ j } \alpha_{ j } $. An elegant proof of this presented in \cite[Thm.~4.1]{fonseca_tartar_1989} can be done through the fundamental theorem of Young measures (\cite[Thm.~3.1]{Müller1999}). By passing to another non-relabelled subsequence of $ u_{ \varepsilon } $, we obtain that $ u_{ \varepsilon } $ generates a Young measure $ \nu $. Since $ u $ is $ \lp^{ p } $-bounded, we have that for almost every $ (t, x ) $, the measure $ \nu_{ ( t, x ) } $ is a probability measure. Moreover the sequence $ W ( u_{ \varepsilon } ) $ is uniformly integrable since 
	\begin{equation*}
	 	0 \leq W ( u_{ \varepsilon } ) \leq \frac{ 1 }{ \varepsilon } W ( u_{ \varepsilon } ) \to 0 
	 \end{equation*}
 	in $ \lp^{ 1 } $. Thus we obtain that for all $ \varphi \in \lp^{ \infty } ( [ 0 , T ] \times \flattorus ) $
 	\begin{equation*}
 		0
 		=
 		\lim_{ \varepsilon \to 0 }
 			\int_{ 0 }^{ T }
 				\int
 					\varphi (t, x )
 					W ( u_{ \varepsilon } (t, x ) )
 				\dd{ x }
 			\dd{ t }
 		=
 		\int_{ 0 }^{ T }
 			\int
 				\varphi ( t, x ) 
				\int_{ \mathbb{ R }^{ N } }
					W ( y )
				\dd{ \nu_{ ( t, x ) } ( y ) }
 			\dd{ x }
 		\dd{ t },
 	\end{equation*}
 	which implies that for almost every $ ( t, x ) $, the probability measure $ \nu_{ ( t, x ) } $ is supported on the set $ \{ \alpha_{ 1 } , \dotsc, \alpha_{ P } \} $. Therefore we can write
 	$ \nu_{ ( t , x ) } = \sum_{ j = 1 }^{ P } \lambda_{ j } \delta_{ \alpha_{ j } } $ for non-negative numbers $ \lambda_{ j } \in [0 ,1 ] $ with $ \sum \lambda_{ j } = 1 $.
 	
 	Now let $ 1 \leq i \leq P $. For every $ f \in \cont_{ 0 } ( \mathbb{ R } ) $, we have that $ f \circ \phi_{ i } \in \cont_{ 0 } ( \mathbb{ R }^{ N } ) $, and thus we can compute that $ \phi_{ i } \circ u_{ \varepsilon } $ generates the Young measure given at almost every point $ ( t, x ) $ by $ \nu_{ ( t , x ) } = \sum \lambda_{ j } \delta_{ \phi_{ i } ( \alpha_{ j } ) } $.
 	But $ \phi_{ i } \circ u_{ \varepsilon } $ converges to $ v_{ i } $ in $ \lp^{ 1 } $, thus especially in measure, which implies by \cite[Cor.~3.2]{Müller1999} that our convex combination already has to be trivial, or in other words, we can write 
 	\begin{equation*}
 		\nu_{ ( t , x ) }
 		=
 		\sum_{ j= 1 }^{ P }
 			\mathds{ 1 }_{ \Omega_{ j } ( t ) } ( x )
 			\delta_{ \alpha_{ j } }
 	\end{equation*}
 	for a time-dependent partition $ ( \Omega_{ j } ( t ) )_{ j = 1 , \dotsc , P } $ of $ \flattorus $. Thus we can write 
 	\begin{equation*}
 		\delta_{ v_{ i } ( t , x ) }
 		=
 		\sum_{ j = 1 }^{ P }
 			\mathds{ 1 }_{ \Omega_{ j } ( t ) } ( x )
 			\delta_{ \phi_{ i } ( \alpha_{ j } ) },
 	\end{equation*}
 	and by defining 
 	$ u \coloneqq \sum_{ j = 1 }^{ P } \mathds{ 1 }_{ \Omega_{ j } ( t ) } ( x ) \alpha_{ j } $, 
 	we obtain that 
 	\begin{equation*} 
 		v_{ i } = 
 		\phi_{ i } \circ u  = \sum_{ j = 1 }^{ P } \mathds{ 1 }_{ \Omega_{ j } ( t ) } ( x ) \sigma_{ i , j } .
 	\end{equation*}
 
 	What is left to show is the energy estimate (\ref{energy_estimate_for_limit_u}) and that partition function $ \chi ( t , x ) \coloneqq \left( \mathds{ 1 }_{ \Omega_{ 1 } ( t )  } ( x ) , \dotsc, \mathds{ 1 }_{ \Omega_{ P } ( t ) } ( x ) \right) $ is of bounded variation.
 	The latter follows from the Fleming--Rishel co-area formula \cite{Fleming_Rishel_coarea_formula} which yields since $ \phi_{ i } \circ u \in \bv \left( ( 0 , T ) \times \flattorus \right) $ that
 	\begin{align*}
 		\infty
 		& >
 		\abs{ 
 			( \partial_{ t } , \nabla )
 			\phi_{ i } \circ u
 		}
 		\left( ( 0 , T ) \times \flattorus \right)
 		\\
 		&
 		=
 		\int_{ 0 }^{ \infty }
 			\hm^{ d } \left(
 				\partial_{ \ast } \left(
 					\left\{
 						( t, x ) 
 						\, \colon \,
 						\phi_{ i } ( u ( t , x ) ) \leq s 
 					\right\}
 				 \right)
 			\right)
 		\dd{ s }
 		\\
 		&
 		\geq
 		\int_{ 0 }^{ \min_{ i \neq j } \sigma_{ i , j } }
 			\hm^{ d } \left(
 				\partial_{ \ast }
 				\left\{
 					( t , x ) \in ( 0 , T ) \times \flattorus 
 					\, \colon \,
 					\chi_{ i } ( t , x ) = 1
 				\right\}
 			\right)
 		\dd{ s }
 		\\
 		&=
 		\min_{ i \neq j }
 			\sigma_{ i , j }
 		\abs{
 			( \partial_{ t } , \nabla ) \chi_{ i }
 		}
 		\left(
 			( 0 , T ) \times \flattorus
 		\right).
 	\end{align*}
 	Here we denote by $ \partial_{ \ast } A $ the measure theoretic boundary of a given measurable set $ A $, as defined for example in \cite[Def.~5.7]{evans_gariepy_measure_theory_and_fine_props}.
 	Since we have $ \sigma_{ i , j } > 0 $ for $ i \neq j $, this proves that $ \chi_{ i } \in \bv \left( ( 0, T ) \times \flattorus \right) $.
 	
 	The energy estimate is a non-trivial consequence of the lower semicontinuity of the variation measure and has been proven by Baldo in \cite{baldo_minimal_interface_criterion}. We will recap the proof since it provides some insight into the geometry of the phases.
\end{proof}

\begin{definition}
	Given a partition $ \left( \Omega_{ i } \right)_{ i = 1 , \dotsc , P } $ of the flat torus $ \flattorus $, where all sets $ \Omega_{ i } $ are of finite perimeter, we define the $ (i,j)$-th interface as $ \Sigma_{ i , j } \coloneqq \partial_{ \ast } \Omega_{ i } \cap \partial_{ \ast } \Omega_{ j } $.
\end{definition}

We already mentioned that we want to apply the lower semicontinuity of the variation measure. Since we can think of $ \phi_{ i } $ as being locally the correct choice for suitable $ i $, we introduce the following notion.

\begin{definition}
	Let $ \mu , \nu $ be regular positive Borel measures on $ \flattorus $. Define the supremum $ \mu \vee \nu $ of $ \mu $ and $ \nu $ as the smallest regular positive measure which is greater or equal to $ \mu $ and $ \nu $ on a Borel subset of $ \flattorus $. By the regularity, we have
	\begin{equation*}
		\mu \vee \nu ( U ) 
		=
		\sup \left\{
			\mu ( V ) + \mu ( W )
			\, \colon \,
			V \cap W = \emptyset,
			V \cup W \subseteq U, 
			V \text{ and } W \text{ are open subsets of } \flattorus
		\right\}
	\end{equation*}
	for any open subset $ U \subseteq \flattorus $.
\end{definition}

It is natural to ask how we can characterize the total variation of $ \psi_{ i } = \phi_{ i } \circ u = \sum \mathds{ 1 }_{ \Omega_{ j } } \sigma_{ i , j } $. For this we note that when going from set $ \Omega_{ j } $ to $ \Omega_{ k } $, our function jumps from $ \sigma_{ i , j } $ to $ \sigma_{ i , k } $. Thus we obtain the following intuitive result.

\begin{lemma}
	\label{rewriting_variation_of_psi_i}
	In the setting of \Cref{initial_convergence_result_multiphase} we can write
	\begin{equation*}
		\abs{ \nabla \psi_{ i } }
		=
		\sum_{ 1 \leq j < k \leq P }
			\abs{ \sigma_{ i , j } - \sigma_{ i , k } }
			\dd{ \hm^{ d - 1 } |_{ \Sigma_{ j , k } } }.
	\end{equation*}
\end{lemma}

The proof can be found in the Appendix. If we now consider the supremum of the measures $ \left( \abs{ \nabla \psi_{ i } } \right)_{ i = 1 , \dotsc, P } $, we notice that all of them are supported on the interfaces $ \Sigma_{ j , k } $, and that by the triangle inequality for the surface tensions, we have 
\begin{equation}
	\label{maximum_of_differences_of_surface_tensions}
	\max_{ 1 \leq i \leq P }
		\abs{ \sigma_{ i , j } - \sigma_{ i , k } }
	=
	\sigma_{ j , k }.
\end{equation}
Thus, we obtain the following.

\begin{proposition}
	\label{supremum_of_abs_nabla_psi_i_is_energy}
	In the situation of \Cref{initial_convergence_result_multiphase} , we have
	\begin{equation*}
		\left(
			\bigvee_{ i = 1 }^{ P }
			\abs{ \nabla \psi_{ i } }
		\right)
		=
		\sum_{ 1 \leq i < j \leq P }
		 \sigma_{ i , j }
		 \dd{ \hm^{ d - 1 } |_{ \Sigma_{ i , j } } }.
	\end{equation*}
\end{proposition}

\begin{proof}
	This follows by combining \Cref{rewriting_variation_of_psi_i} and \Cref{supremum_of_measures_lemma} with the above equation (\ref{maximum_of_differences_of_surface_tensions}).
\end{proof}

Collecting our observations, we can finish our arguments.

\begin{proof}[Continuation of the proof for \Cref{initial_convergence_result_multiphase}]
	We are left with proving the estimate (\ref{energy_estimate_for_limit_u}). We first note that as for the proof of (\ref{l1_estimate_on_nabla_phi_composed_u}), it holds that for any open subset $ U $ of the flat torus, we have for almost every time $ t $ the estimate
	\begin{equation*}
		\liminf_{ \varepsilon \to 0 } 
			\int_{ U }
				\frac{ 1 }{ \varepsilon }
				W ( u_{ \varepsilon } ( t )  )
				+
				\frac{ \varepsilon }{ 2 }
				\abs{ \nabla u_{ \varepsilon } ( t ) }^{ 2 }
			\dd{ x }
		\geq
		\abs{ \nabla \psi_{ i } ( t ) } ( U ).
	\end{equation*}
	Since
	\begin{equation*}
		\left(
		\bigvee_{ i = 1 }^{ P }
			\abs{ \nabla \psi_{ i } } 
		\right) 
		( \flattorus )
		=
		\sup \left\{
			\sum_{ i = 1 }^{ P }
				\abs{ \nabla \psi_{ i } } ( U_{ i } )
			\, \colon \,
			( U_{ i } )_{ i } \text{ are disjoint open subsets of } \flattorus
		\right\},
	\end{equation*}
	we finally deduce
	\begin{align*}
		\esssup_{ 0 \leq t \leq T }
			\energy ( u ( t ) )
		& =
		\esssup_{ 0 \leq t \leq T }
			\sum_{ 1 \leq i < j \leq P }
				\sigma_{ i , j }
				\hm^{ d - 1 } ( \Sigma_{ i , j } ( t ) )
		\\
		& = \esssup_{ 0 \leq t \leq T }
		\left(
			\bigvee_{ i = 1 }^{ P }
				\abs{ \nabla \psi_{ i } ( t ) }
		\right) ( \flattorus )
		\\
		& \leq
		\esssup_{ 0 \leq t \leq T }
			\liminf_{ \varepsilon \to 0 }
				\energy_{ \varepsilon } ( u_{ \varepsilon } ( t ) )
		\\
		& \leq
		\energy_{ 0 }.
	\end{align*}
	The last inequality is due the energy dissipation inequality (\ref{energy_dissipation_sharp}).
\end{proof}

Nextup, we want to prove a stronger convergence of $ u_{ \varepsilon } $ to $ u $. This will let us prove that $ u $ achieves to initial data (and the existence of normal velocities?).

\begin{lemma}
	In the situation of \Cref{initial_convergence_result_multiphase} we have 
	$ \psi_{ i }^{ \varepsilon } \in \wkp^{ 1 , 2 } \left(
		[ 0 , T ] ; \lp^{ 1 } ( \flattorus )
	\right)
	$
	with the corresponding estimate
	\begin{equation}
		\label{l2_estimate_on_partial_t_psi_i}
		\left(
			\int_{ 0 }^{ T }
				\left(
					\int
						\abs{ \partial_{ t } \psi_{ i }^{ \varepsilon } }
					\dd{ x }
				\right)^{ 2 }
			\dd{ t }
		\right)^{ 1/2 }
		\lesssim
		\energy_{ \varepsilon } ( u_{ \varepsilon } ( 0 ) ).
	\end{equation}
	Furthermore the sequence $ u_{ \varepsilon } $ is precompact in 
	$ \cont \left(
		[ 0 , T ] ; \lp^{ 2 } ( \flattorus ; \mathbb{ R }^{ N } )
	\right) $.
	In particular we get that $ u $ achieves the initial data in 
	$ \cont \left( [ 0 , T ] ; \lp^{ 2 } ( \flattorus ; \mathbb{ R }^{ N } )
	\right) $.
\end{lemma}

\begin{remark}
	This statement is almost similar to its twophase equivalent \Cref{l2_bound_on_psi_varepsilon} and the proof uses a similar strategy.
\end{remark}

\begin{proof}
	\begin{description}[wide=0pt]
		\item[Step 1:] Estimate (\ref{l2_estimate_on_partial_t_psi_i}) holds
		
		We compute that by Hölder's inequality and the energy dissipation inequality (\ref{energy_dissipation_sharp})
		\begin{align*}
			\int_{ 0 }^{ T }
				\left(
					\int
						\abs{ \partial_{ t } \psi_{ i }^{ \varepsilon } }
					\dd{ x }
				\right)^{ 2 }
			\dd{ t }
			& \leq
			\int_{ 0 }^{ T }
				\left(
					\int
						\sqrt{ 2 W ( u_{ \varepsilon } ) }
						\abs{ \partial_{ t } u_{ \varepsilon } }
					\dd{ x }
				\right)^{ 2 }
			\dd{ t }
			\\
			& =
			\int_{ 0 }^{ T }
				\int
					\frac{ 2 }{ \varepsilon }
					W ( u_{ \varepsilon } )
				\dd{ x }
				\int
					\varepsilon 
					\abs{ \partial_{ t } u_{ \varepsilon } }^{ 2 }
				\dd{ x }
			\dd{ t }
			\\
			& \leq
			2 \energy_{ \varepsilon } ( u_{ \varepsilon } ( 0 ) )
			\int_{ 0 }^{ T }
				\int
					\varepsilon 
					\abs{ \partial_{ t } u_{ \varepsilon } }^{ 2 }
				\dd{ x }
			\dd{ t }
			\\
			& \leq
			2 \energy_{ \varepsilon } ( u_{ \varepsilon } ( 0 ) )^{ 2 }.
		\end{align*}
		By estimate (\ref{l1_estimate_on_nabla_phi_composed_u}), we especially obtain $ \psi_{ i }^{ \varepsilon } \in \lp^{ 2 } \left( [ 0 , T ] ; \lp^{ 1 } ( \flattorus ) \right) $.
		
		\item[Step 2:] The sequence $ \psi_{ i }^{ \varepsilon } $ is precompact in $ \cont \left( [ 0 , T ] ; \lp^{ 1 } ( \flattorus ) \right) $.
		
		This follows exactly as in the twophase case from the embedding of 
		$ \wkp^{ 1 , 2 } \left( [ 0 , T ] ; \lp^{ 1 } ( \flattorus ) \right) $
		into $ \cont^{ 1/2 } \left( [ 0 , T ] ; \lp^{ 1 } ( \flattorus ) \right) $.
		
		\item[Step 3:] The sequence $ u_{ \varepsilon } $ converges to $ \sum_{ i } \chi_{ i } \mathds{ 1 }_{ \Omega_{ i } } \alpha_{ i } $ in measure uniformly in time.
		
		Let $ \rho > 0 $. Then by definition of $ \phi_{ i } $, there exists some $ \delta > 0 $ such that if  
		$ \abs{ v - \alpha_{ i } } > \rho $ holds for all $ 1 \leq i \leq P $, then we already have $ \phi_{ v } > \delta $ for all $ 1 \leq i \leq P $.
		Therefore we can estimate
		\begin{align*}
			\esssup_{ 0 \leq t \leq T }
				\lm^{ d } \left(
					\left\{
						x 
						\, \colon \,
						\abs{ u_{ \varepsilon } - \sum_{ i } \mathds{ 1 }_{ \Omega_{ i } \alpha_{ i } } } > \rho 
					\right\}
				\right)
			& = 
			\esssup_{ 0 \leq t \leq T }
				\sum_{ i = 1 }^{ P }
					\lm^{ d }
						\left(
							\left\{
								x \in \Omega_{ i }
								\, \colon \,
								\abs{ u_{ \varepsilon } - \alpha_{ i } }
								> \rho
							\right\}	
						\right)
			\\
			& \leq
				\esssup_{ 0 \leq t \leq T }
					\sum_{ i = 1 }^{ P }
						\lm^{ d } \left(
							\left\{
								x \in \Omega_{ i }
								\, \colon \,
								\phi_{ i } ( u_{ \varepsilon } ) > \delta 
							\right\}
						\right)
			\\
			& \leq
			\esssup_{ 0 \leq t \leq T }
				\frac{ 1 }{ \delta }
				\sum_{ i = 1 }^{ P }
					\int_{ \Omega_{ i } }
						\abs{ \psi_{ i }^{ \varepsilon } }
					\dd{ x }
			\\
			& \leq
			\esssup_{ 0 \leq t \leq T }
				\frac{ 1 }{ \delta }
				\sum_{ i = 1 }^{ P }
					\int
						\abs{ \psi_{ i }^{ \varepsilon } - \psi_{ i } }
					\dd{ x },
		\end{align*}
		which converges to $ 0 $ by Step 2.
		
		\item[Step 4:] The sequence $ u_{ \varepsilon }^{ 2 } $ is equiintegrable uniformly in time
		
		This follows as in the twophase case as well.
		
		\item[Step 5:] The sequence $ u_{ \varepsilon } $ converges in $ \cont \left( [ 0 , T ] ; \lp^{ 2 } ( \flattorus ; \mathbb{ R }^{ N } ) \right) $.
		
		Here the proof does not change as well.
	\end{description}
\end{proof}

With these estimate, we can now prove the existence of normal velocities $ V_{ i } $ for the evolving sets $ \Omega_{ i } $ if we assume that the time-integrated energies converges, written out as in (\ref{energy_convergence}), but now for the multiphase energy given by (\ref{definition_of_multiphase_energy}).

\begin{proposition}
	\label{existence_and_square_integrability_of_velocities_multiphase}
	In the situation of \Cref{initial_convergence_result_multiphase} and under the energy convergence assumption (\ref{energy_convergence}), we have that for every $ 1 \leq i \leq P $, the signed measure $ \partial_{ t } \chi_{ i } $ is absolutely continuous with respect to the measure $ \abs{ \nabla \chi_{i } } \dd{ t } $ and the corresponding density $ V_{ i } $ is square integrable with the corresponding estimate
	\begin{equation}
		\label{velocity_l2_estimate}
		\int_{ 0 }^{ T }
			\int
				V_{ i }^{ 2 }
			\abs{ \nabla \chi_{ i } }
		\dd{ t }
		\lesssim
		\energy_{ 0 }.
	\end{equation}
\end{proposition}

\begin{proof}
	The proof proceeds in four steps. First we show that $ \partial_{ t } \psi_{ i } $ is absolutely continuous with respect to the energy measure. Afterwards, we show that we can already estimate $ \abs{ \partial_{ t } \chi_{ i } } $ by $ \abs{ \partial_{ t } \psi_{ i } } $. To finish the argument, we then we have to argue that $ \partial_{ t } \chi_{ i } $ is already singular with respect to every part of the energy which is not contained in $ \abs{ \nabla \chi_{ i } } \dd{ t } $.
	 
	\begin{description}[wide=0pt]
		\item[Step 1:] The signed measure $ \partial_{  t } \psi_{ i } $ is absolutely continuous with respect to the energy measure $ \energy ( \cdot, u ) \dd{t } $ with square-integrable density.
		
		For this let $ \varphi $ be a testfunction. Then we can estimate by Hölder's inequality
		\begin{align*}
			\int_{ 0 }^{ T }
				\int
					\varphi
					\partial_{ t } \psi_{ i }
			& =
			\liminf_{ \varepsilon \to 0 }
				\int_{ 0 }^{ T }
					\int
						\varphi
						\partial_{ t } \psi_{ i }^{ \varepsilon }
					\dd{ x }
				\dd{ t }
			\\
			& \leq
			\liminf_{ \varepsilon \to 0 }
				\left(
					\int_{ 0 }^{ T }
						\int
							\varepsilon 
							\abs{ \partial_{ t } u_{ \varepsilon } }^{ 2 }
						\dd{ x }
					\dd{ t }
				\right)^{ 1/2 }
				\left(
					\int_{ 0 }^{ T }
						\int
							\varphi^{ 2 }
							\frac{ 1 }{ \varepsilon }
							2 W ( u_{ \varepsilon } )
						\dd{ x }
					\dd{ t }
				\right)^{ 1/2 }
			\\
			& \leq
			\sqrt{ 2 \energy_{ 0 } }
			\left(
				\int_{ 0 }^{ T }
					\energy ( u ; \varphi )
				\dd{ t }
			\right)^{ 1/2 }.
		\end{align*}
		Here the last inequality is due to the energy dissipation (\ref{energy_dissipation_sharp})
		and the proof of our claim is therefore complete.
		
		\item[Step 2:] For $ d_{ i } \coloneqq \min_{ j \neq i } $, we have that $ d_{ i } \abs{ \partial_{ t } \chi_{ i } } \leq \abs{ \partial_{ t } \psi_{ i } } $.
		
		Using the disintegration Theorem \cite[Thm.~3.103]{ambrosio_fusco_pallara_functions_of_bv_and_free_discontinuity_problems} and the Fleming--Rishel co-area formula, we have that for any open set $ U \subseteq [ 0 , T ] \times \flattorus $ that
		\begin{align*}
			\abs{
				\partial_{ t } \psi_{ i }
			} ( U ) 
			& =
			\int
				\abs{ 
					\partial_{ t } \psi_{ i } ( \cdot , x )
				} ( \pi_{ x } ( U ) ) 
			\dd{ x }
			\\
			& =
			\int
				\int_{ 0 }^{ \infty }
					\hm^{ 0 } \left(
						\left\{
							t 
							\, \colon \,
							\phi_{ i } 
							\left( \sum_{ j } \chi_{ j } \alpha_{ j } \right) > s,
							( t, x ) \in U
						\right\}
					\right)
				\dd{ s }
			\dd{ x }
			\\
			& \geq
			\int
				\int_{ 0 }^{ d_{ i } }
					\hm^{ 0 }
						\left(
							\left\{
								t 
								\, \colon \,
								\chi_{ i } ( t , x ) = 1,
								( t, x ) \in U
							\right\}
						\right)
				\dd{ s }
			\dd{ x }
			\\
			& =
			d_{ i }
			\int
				\int_{ 0 }^{ \infty }
					\hm^{ 0 } \left(
						\left\{
							t 
							\, \colon \,
							\chi_{ i } ( t , x ) > s , ( t , x ) \in U
						\right\}
					\right)
				\dd{ s }
			\dd{ x }
			\\
			& =
			d_{ i }
			\abs{ \partial_{ t } \chi_{ i } } ( U ).
		\end{align*}
		Here the set $ \pi_{ x } ( U ) $ denotes the set of all $ t $ such that $ ( t , x ) $ is an element of $ U $.
		By an approximation argument, this inequality holds for every testfunction as well, proving the claim.
		
		\item[Step 3:] The signed measure $ \partial_{ t } \chi_{ i } $ is singular to the wrong parts of $ \energy ( u ; \cdot ) $. More precisely we claim that if $ 1 \leq j < k \leq P $ and $ i \notin \{ j , k \} $, then the measures 
		$ \hm^{ d - 1 } |_{ \Sigma_{ j , k } } \dd{ t } $ and $ \abs{ \partial_{ t } \chi_{ i } } $ are mutually singular.
		
		We again write $ \abs{ \nabla \chi }_{ d + 1 } $ for the space derivative in time and space and $ \abs{ \nabla \chi }_{ d } $ for the space derivative for some fixed time $ t $, which is defined for almost every time. Moreover, we denote by $ \tilde{ \Omega }_{ i } $ the set in time and space such that
		$ \chi_{ i } ( t , x ) = \mathds{ 1 }_{ \tilde{ \Omega }_{ i } } ( t , x ) $
		and by $ \tilde{ \Sigma }_{ i , j } $ the corresponding interfaces.
		
		By \Cref{identities_for_measure_theoretic_boundaries} we can then write
		\begin{equation*}
			\abs{ \partial_{ t } \chi_{ i } }
			\leq
			\abs{ ( \partial_{ t } , \nabla ) \chi_{ i } }
			=
			\sum_{ l \neq i }
				\hm^{ d } |_{ \partial_{ \ast } \tilde{ \Omega }_{ i } \cap \partial_{ \ast } \tilde{ \Omega }_{ l } }.
		\end{equation*}
		But for all $ l \neq i $, we have again by \Cref{identities_for_measure_theoretic_boundaries} that either 
		\begin{equation*}
			\abs{ ( \partial_{ t } , \nabla ) \chi_{ j } } ( \tilde{ \Sigma }_{ i , l } ) = 0 
			\quad \text{or} \quad
			\abs{ ( \partial_{ t } , \nabla ) \chi_{ k } } ( \tilde{ \Sigma }_{ i , l } ) = 0.
		\end{equation*}
		Without loss of generality we assume the former. 
		Then it follows that $ \abs{ \nabla \chi_{ j } }_{ d + 1 } \left( \tilde{ \Sigma }_{ i , l } \right) = 0 $ and therefore we have
		\begin{align*}
			\hm^{ d - 1 } |_{ \Sigma_{ j , k } } \dd{ t } ( \tilde{ \Sigma }_{ i , l } )
			& =
			\frac{ 1 }{ 2 } \left(
				\abs{ \nabla \chi_{ j } }_{ d }
				+
				\abs{ \nabla \chi_{ k } }_{ d }
				-
				\abs{ \nabla ( \chi_{ j } + \chi_{ k } ) }_{ d }
			\right)
			\dd{ t }
			\left( \tilde{ \Sigma }_{ i , l }\right)
			\\
			& = 
			\frac{ 1 }{ 2 } \left(
				\abs{ \nabla \chi_{ j } }_{ d+1 }
				+
				\abs{ \nabla \chi_{ k } }_{ d +1 }
				-
				\abs{ \nabla ( \chi_{ j } + \chi_{ k } ) }_{ d+ 1 }
			\right) \left( \tilde{ \Sigma }_{ i , l } \right)
			\\
			& = 
			\frac{ 1 }{ 2 } \left( 
				\abs{ \nabla \chi_{ k } }_{ d + 1 } \left( \tilde{ \Sigma } _{ i , l } \right)
				-
				\abs{ \nabla \chi_{ k } }_{ d + 1 } 
			\right)
			\left( \tilde{ \Sigma } _{ i , l } \right)
			= 0.		
		\end{align*}
		This proves the desired singularity.
		
		\item[Step 4:] We have 
		$ \abs{ \partial_{ t } \chi_{ i } } 
		\leq \abs{ \nabla \chi_{ i } } \dd{ t } $ and estimate (\ref{velocity_l2_estimate}) holds.
		
		Combining Step 1 and Step 2, we obtain that $ \abs{ \partial_{ t } \chi_{ i } } $ is absolutely continuous with respect to the energy measure $ \energy ( u ; \cdot ) $. Moreover we can write
		\begin{equation*}
			\energy ( u ; \cdot ) \dd{ t }
			=
			\sum_{ j \neq i }
				\sigma_{ i , j }
				\hm^{ d - 1 } |_{ \Sigma_{ i , j } }
				\dd{ t }
			+
			\sum_{ 1 \leq j < k \leq P , j, k \neq i }
				\sigma_{ j , k }
				\hm^{ d- 1 } |_{ \Sigma_{ j , k } }
				\dd{ t }.
		\end{equation*}
		In the last term, the second summand is by Step 3 singular to $ \abs{ \partial_{ t } \chi_{ i } } $ and the first summand is bounded by $ \abs{ \nabla \chi_{ i } } \dd{ t } $, which proves that $ \partial_{ t } \chi_{ i } $ is absolutely continuous with respect to $ \abs{ \nabla \chi_{ i } } \dd{ t } $.
		
		The estimate (\ref{velocity_l2_estimate}) is now a consequence of our previous arguments combined with a duality estimate. Fix some $ K > 0 $ and let $ \varphi_{ n } $ be a sequence of testfunctions which converges in 
		$ \lp^{ 2 } \left( \abs{ \nabla \chi_{ i } } \dd{ t } \right) $ to the function
		$ V_{ i } \mathds{ 1 }_{ \abs{ V_{ i } } \leq K } \mathds{ 1 }_{ \mathrm{supp} \abs{ \partial_{ t } \chi_{ i } } } $. Then combining the previous steps, we can estimate
		\begin{align*}
			\int_{ 0 }^{ T }
				\int
					V_{ i }^{ 2 } \mathds{ 1 }_{ \abs{ V_{ i } } \leq K }
				\abs{ \nabla \chi_{ i } }
			\dd{ t }
			& =
			\liminf_{ n \to \infty }
				\abs{
					\int_{ 0 }^{ T }
						\int
							V_{ i } \varphi_{ n } 
						\abs{ \nabla \chi_{ i } }
					\dd{ t }
				}
			\\
			& = 
			\liminf_{ n \to \infty }
				\abs{
					\int_{ 0 }^{ T }
						\int
							\varphi_{ n } \partial \chi_{ i }
				}
			\\
			& \lesssim
			\liminf_{ n \to \infty }
				\int_{ 0 }^{ T }
					\int
						\varphi_{ n }^{ 2 }
					\abs{ \partial_{ t } \psi_{ i } }
			\\
			& \leq
			\sqrt{ 2 \energy_{ 0 } }
			\liminf_{ n \to \infty }
				\left(
					\int_{ 0 }^{ T }
						\energy ( u ; \varphi_{ n }^{ 2 } )
					\dd{ t }
				\right)^{ 1/2 }
			\\
			& \lesssim
			\sqrt{ 2 \energy_{ 0 } }
			\left(
				\int_{ 0 }^{ T }
					\int
						V_{ i }^{ 2 }
						\mathds{ 1 }_{ \abs{ V_{ i } } \leq K }
					\abs{ \nabla \chi_{ i } }
				\dd{ t }
			\right)^{ 1 / 2 }.
		\end{align*}
		This proves by the monotone convergence theorem the desired claim.
	\end{description} 
\end{proof}

Nextup, we want to capture an important Lemma called the \enquote{equipartition of energy} which states that under the energy convergence assumption (\ref{energy_convergence}), it must already hold that
\begin{equation*}
	\frac{ \varepsilon }{ 2 } \abs{ \nabla u_{ \varepsilon } }^{ 2 }
	-
	\frac{ 1 }{ \varepsilon } W ( u_{ \varepsilon } )
	\rightharpoonup^{ \ast }
	0
\end{equation*}
holds in the distributional sense. The proof is similar to the twophase case \Cref{equipartition_of_energies}.

VLT HIER PAPER VON ILMANEN ZITIEREN

\begin{lemma}
	\label{equipartition_of_energies_multiphase}
	In the situation of \Cref{initial_convergence_result_multiphase} and under the energy convergence assumption (\ref{energy_convergence}), we have for any continuous $ \varphi \in \cont ( \flattorus ) $ that
	\begin{align*}
		\energy ( u ; \varphi )
		=
		\lim_{ \varepsilon \to 0 }
			\energy_{ \varepsilon } ( u_{ \varepsilon } ; \varphi )
		& =
		\lim_{ \varepsilon \to 0 }
			\int
				\varphi
				\varepsilon
				\abs{ \nabla u_{ \varepsilon } }^{ 2 }
			\dd{ x }
		\\
		& =
		\lim_{ \varepsilon \to 0 }
			\int
				\varphi
				\frac{ 1 }{ \varepsilon } 2 W ( u_{ \varepsilon } )
			\dd{ x }
		\\
		& =
		\lim_{ \varepsilon \to 0 }
			\int
				\varphi
				\sqrt{ 2 W ( u_{ \varepsilon } ) }
				\abs{ \nabla u_{ \varepsilon } }
			\dd{ x }
	\end{align*}
	for almost every time $ 0 \leq t \leq T $.
\end{lemma}

\subsection{Convergence to multiphase mean curvature flow}

We start by defining a $ \bv $-formulation for motion by multiphase mean curvature flow under the simplifying assumption that the mobilities are already fixed by the surface tensions through the equation
\begin{equation}
	\label{mobilites_inverse_of_surface_tensions}
	\mu_{ i , j } =\frac{ 1 }{ \sigma_{ i , j } }. 
\end{equation}

\begin{definition}
	Fix some finite time horizon $ T < \infty $, a $ P \times P $ matrix of surface tensions $ \sigma $ and initial data $ \chi^{ 0 } \colon \flattorus \to \{ 0 , 1 \}^{ P } $ with $ \energy_{ 0 } \coloneqq ( \chi^{ 0 } ) $ and $ \sum_{ i = 1 }^{ P } \chi_{ i }^{ 0 } = 1 $. We say that
	\begin{equation*}
		\chi \in \cont \left(
			[ 0 , T ]
			;
			\lp^{ 2 } \left( \flattorus ; \{ 0 , 1 \}^{ P } \right)
		\right)
	\end{equation*}
	with $ \esssup_{ 0 \leq t \leq T } \energy ( \chi ) $ and $ \sum_{ i = 1 }^{ P } \chi_{ i } $ \emph{moves by mean curvature} if there exists normal velocities $ V_{ i } \in \lp^{ 2 } ( \abs{ \nabla \chi_{ i } } \dd{ t } ) $ with
	\begin{equation*}
		\int_{ 0 }^{ T }
			\int
				V_{ i }^{ 2 }
			\abs{ \nabla \chi_{ i } }
		\dd{ t }
		< \infty 
	\end{equation*} 
	such that
	\begin{enumerate}
		\item For all 
		$ \xi \in \cont_{ \mathrm{c} }^{ \infty } \left(
			( 0 , T ) \times \flattorus ; \mathbb{ R }^{ d }
		\right)
		$, we have 
		\begin{align}
			\label{distributional_equation_mmcf}
			\sum_{ 1 \leq i < j \leq P }
				\sigma_{ i , j }
				\int_{ 0 }^{ T }
					\int
						&
						\left(
							V_{ i } \inner*{ \xi }{ \nu_{ i } }
							+
							\inner*{ \diff \xi }{ \mathrm{Id} - \nu_{ i } \otimes \nu_{ i } }
						\right)
						\times
					\\
				\notag
					& \frac{1}{ 2 }
					\left(
						\abs{ \nabla \chi_{ i } }
						+
						\abs{ \nabla \chi_{ j } }
						-
						\abs{ \nabla ( \chi_{ i } + \chi_{ j } ) }
					\right)
				\dd{ t }
			=0,			
		\end{align}
		where $ \nu_{ i } $ is the outer unit normal of $ \chi_{ i } $.
		
		\item 
		The functions $ V_{ i } $ are the normal velocities of the interfaces in the sense that
		\begin{equation*}
			\partial_{ t } \chi_{ i }
			=
			V_{ i } \abs{ \nabla \chi_{ i } } \dd{ t }
		\end{equation*}
		holds in the distributional sense on $ ( 0 , T ) \times \flattorus $.
		
		\item
		The initial data is achieved in the space $ \cont \left( [ 0 , T ] ; \lp^{ 2 } ( \flattorus ) \right) $.
	\end{enumerate}
\end{definition}

	Since (\ref{distributional_equation_mmcf}) is quite the long equation, we want to motivate it. Assuming that everything is nice and smooth, we have by the Gauss-Green theorem on surfaces \cite[Thm.~11.8]{maggi_sets_of_finite_perimeter} that
	\begin{equation*}
		\int_{ \Sigma_{ i , j } }
			\int 
				\inner{ \diff \xi }{ \mathrm{Id} - \nu \otimes \nu }
			\dd^{\hm^{ d- 1 }}
		=
		\int_{ \Sigma_{ i , j } }
			\int
				H_{ i , j } \inner*{ \xi }{ \nu_{ i } }
			\dd{\hm^{ d- 1 }}
		+
		\int_{ \Gamma_{ i , j } }
			\int
				\inner*{ \xi }{ \nu_{ \Gamma_{ i , j } } }
			\dd{ \hm^{ d - 2 } }.
	\end{equation*}
	Here $ \Gamma_{ i , j } $ denotes the boundary of the surface $ \Sigma_{ i , j } $, which we expect to only have significant contribution at triple junctions. But then Herring's angle condition (\ref{herrings_angle_condition}) tells us that the boundary terms cancel out (HIER NOCHMAL TIM WEGEN DEN NORMALEN FRAGEN). But now we integrate at each interface over the quantity
	\begin{equation*}
		(V_{ i } - H_{ i , j } ) \inner*{ \xi }{ \nu_{ i } },
	\end{equation*}
	which is zero by equation (\ref{v_is_equal_to_h}) combined with the 
	assumption (\ref{mobilites_inverse_of_surface_tensions}).
	
	Our main goal will be to arrive at a similar conditional convergence result 
	to multiphase mean curvature flow in the sense of the above definition. 
	This is captured by the following.
	
	\begin{theorem}
		\label{convergence_to_multiphase_mcf}
		Let a smooth multiwell potential $ W \colon \mathbb{ R }^{ N } \to [ 0, 
		\infty ) $ satisfy the assumptions 
		(\ref{polynomial_growth})-(\ref{perturbation bound}). Let $ T < \infty 
		$ be an arbitrary finite time horizon. Given a sequence of initial data 
		$ u_{ \varepsilon }^{ 0 } \colon \flattorus \to \mathbb{ R }^{ N } $ 
		approximating a partition 
		$ \chi^{ 0 } \in \bv \left( \flattorus ; \{ 0 , 1 \}^{ P } \right) $ 
		in the sense that 
		$ u_{ \varepsilon }^{ 0 } \to u^{ 0 } =  \sum_{ 1 \leq i \leq P } 
		\chi_{ i }^{ 0 } \alpha_{ i } $ 
		holds pointwise almost everywhere and 
		\begin{equation*} 
		\energy_{ 0 } 
		\coloneqq 
		\energy ( \chi^{ 0 } ) 
		= 
		\lim_{ \varepsilon \to 0 } 
			\energy_{ \varepsilon } ( u_{ \varepsilon }^{ 0 } ) 
		< 
		\infty,
		\end{equation*}
		we have that for 
		some subsequence of solutions to the Allen--Cahn equation
		(\ref{allen_cahn_eq}) $ u_{\varepsilon } $ with initial datum $ u_{ 
		\varepsilon }^{ 0 } $, there exists a time-dependent partition $ \chi $ 
		with 
		$ \chi \in \bv \left( ( 0 , T ) \times \flattorus ; \{ 0 , 1 \}^{ P } 
		\right) $ and
		$ \chi 
		\in \cont \left( [ 0 , T ] ; \lp^{ 2 } \left( \flattorus ;  \{ 0 , 1 
		\}^{ P } \right) \right) $ such that $ u_{ \varepsilon } $ converges to 
		$ u \coloneqq \sum_{ 1 \leq i \leq P } \chi_{ i } \alpha_{ i } $ almost 
		everyhwere. Moreover $ u $ assumes the initial data $ u^{ 0 } $ in $ 
		\cont \left( [ 0, T ] ; \lp^{ 2 }( \flattorus ) \right) $. If we 
		additionally assume that the 
		time-integrated energies converge (\ref{energy_convergence}), then $ 
		\chi $ moves by mean curvature in the sense of \Cref{motion_by_mcv}.
	\end{theorem} 
	
\subsection{Localization estimates}
\label{section_localization_estimates}
In order to prove convergence of the curvature and velocity term, we want to reduce the multiphase case to the twophase case. The central idea here is to cover the flat torus with a suitable covering of balls and argue that, up to an arbitrarily small error as long as the balls are small enough, we can choose for each ball majority phases $ i, j $ such that the multiphase mean curvature looks like a twophase mean curvature on the ball, see \Cref{figure_localization_of_mmcf}.

\begin{figure}[h]
	\centering
\begin{tikzpicture}
	
	\draw[very thick]  (1,-1) -- (2, -2 );
	\draw[very thick]  (4,-2) --(5,-1);
	\draw[very thick]  (1,-5) --(2,-4);
	\draw[very thick] (4,-4)--(5, -5);
	
	\draw[very thick](2,-2)--(4,-2);
	\draw[very thick] (4,-2)--(4,-4);
	\draw[very thick] (4, -4)--(2, -4);
	\draw[very thick] (2, -4) -- (2, -2);
	
	\begin{comment}
	
	\draw[red] (1,-1) circle (0.5cm);
	\draw[red] (1.5,-1) circle (0.5cm);
	\draw[red] (2,-1) circle (0.5cm);
	\draw[red] (2.5,-1) circle (0.5cm);
	\draw[red] (3,-1) circle (0.5cm);
	\draw[red] (3.5,-1) circle (0.5cm);
	\draw[red] (4,-1) circle (0.5cm);
	\draw[red] (4.5,-1) circle (0.5cm);
	\draw[red] (5,-1) circle (0.5cm);
	\draw[red] (1,-1.5) circle (0.5cm);
	\draw[red] (1.5,-1.5) circle (0.5cm);
	\draw[red] (2,-1.5) circle (0.5cm);
	\draw[red] (2.5,-1.5) circle (0.5cm);
	\draw[red] (3,-1.5) circle (0.5cm);
	\draw[red] (3.5,-1.5) circle (0.5cm);
	\draw[red] (4,-1.5) circle (0.5cm);
	\draw[red] (4.5,-1.5) circle (0.5cm);
	\draw[red] (5,-1.5) circle (0.5cm);
	\end{comment}
	\draw[green,thick] (1,-1.5) circle (0.5cm);	
	\draw[green,thick] (1.5,-2) circle (0.5cm);	
	\draw[red,thick] (2,-2) circle (0.5cm);	
	\draw[blue,thick] (2.5,-2) circle (0.5cm);	
	\draw[blue,thick] (3,-2) circle (0.5cm);	
	\draw[blue,thick] (3.5,-2) circle (0.5cm);	
	\draw[red,thick] (4,-2) circle (0.5cm);	
	\draw[yellow,thick] (4.5,-2) circle (0.5cm);	
	\draw[yellow,thick] (5,-1.5) circle (0.5cm);	
	
	\node at (3,-3) {$\Omega_{ 1 }$};
	\node at (1,-3) {$\Omega_{2}$};
	\node at (3,-1) {$\Omega_{3}$};
	\node at (5,-3) {$\Omega_{4}$};
\end{tikzpicture}
\caption{Localization of multiphase mean curvature flow. For the green balls, we choose the majority phase (2,3), for the blue ones (1,3) and for the yellow balls (3,4). The red balls however give us an error.}

\label{figure_localization_of_mmcf}
\end{figure}

To formulate this rigorously let $ r > 0 $ and define the covering $ \beta_{ r } $ of $ \flattorus $ by
\begin{equation*}
	\mathcal{B}_{ r } \coloneqq
	\left\{
		B_{ r } ( c ) 
		\, \colon \,
		c \in \mathcal{ L }_{ r }
	\right\},
\end{equation*}
where the set of centers $ \mathcal{ L }_{ r } $ is given by $ \mathcal{ L }_{ 
r } \coloneqq \flattorus \cap (r/\sqrt{ d }) \mathbb{ Z }^{ d } $. Moreover let 
$ \rho_{ B } $ be a smooth cutoff for the ball $ B $ with support in the ball 
with the same center, but double the radius.

Additionally to choosing a majority phase, we can also argue that along the 
chosen majority phase, we have a local flatness. Thus we may approximate the 
outer unit normal up to an arbitrarily small error by a constant unit vector. 
This is captured by the following Lemma.

\begin{lemma}
	\label{localization_lemma_with_normals}
	For every $ \delta > 0 $ and every partition $ \chi \colon \flattorus \to \{ 0 , 1 \}^{ P } $ such that $ \chi_{ i } \in \bv ( \flattorus ) $ holds for all $ 1 \leq i \leq P $, there exist some $ r_{ 0 } > 0 $ such that for all $ 0 < r < r_{ 0 } $, we find for every ball $ B \in \mathcal{B}_{ r } $ some unit vector $ \nu_{ B } $ such that
	\begin{equation*}
		\sum_{ B \in \mathcal{B}_{ r } }
			\min_{ i \neq j }
				\int
					\rho_{ B }
					\abs{ \nu_{ i } - \nu_{ B } }^{ 2 }
				\abs{ \nabla \chi_{ i } }
				+
				\int
					\rho_{ B }
					\abs{ \nu_{ j } + \nu_{ B } }^{ 2 }
				\abs{ \nabla \chi_{ j } }
				+
				\sum_{ k \notin \{ i , j \} }
					\int 
						\rho_{ B }
					\abs{ \nabla \chi_{ k } }
		\lesssim
		\delta \energy ( \chi )
	\end{equation*}
\end{lemma}
	
Note that by \Cref{identities_for_measure_theoretic_boundaries}, integrating  $ \abs{ \nabla \chi_{ k } } $ over the sum of all $ k \notin \{ i , j \} $ equates to summing over all interfaces which are not the $ (i,j)$-th interface. Moreover the second summand is in some sense unnecessary, since the last summand provides us with a localization on the $ (i,j)$-th interface, on which we have $ \nu_{ i } = - \nu_{ j } $.
However it is convenient to keep it so that we do now have to repeat this argument.

\begin{remark}
	\label{localization_estimate_weaker}
This estimates implies also the smallness of
\begin{equation*}
	\sum_{ B \in \mathcal{ B }_{ r } }
		\min_{ i }
			\abs{
			\energy ( \chi; \rho_{ B } )
			-
			\int
				\rho_{ B }
			\abs{ \nabla \psi_{ i } }
		}
	=
	\sum_{ B \in \mathcal{ B }_{ r } }
		\energy ( \chi ; \rho_{ B } )
		-
		\max_{ i }
			\int
				\rho_{ B }
			\abs{ \nabla \psi_{ i } }
\end{equation*}
in the same sense as in the above \Cref{localization_lemma_with_normals}. 
Notice that the equality follows for example from 
\Cref{supremum_of_abs_nabla_psi_i_is_energy}, which yields that $ \abs{ \nabla 
\psi_{ i } } \leq \energy ( \chi ; \cdot )$. The smallness follows since by 
\Cref{rewriting_variation_of_psi_i}, we have for every $ i \neq j $ that
\begin{align*}
	&
	\energy ( \chi ; \rho_{ B } ) 
	-
	\int
		\rho_{ B }
	\abs{ \nabla \psi_{ i } }
	\\
	={} &
	\sum_{ 1 \leq k < l \leq P }
		\sigma_{ k , l }
		\int_{ \Sigma_{ k , l } }
			\rho_{ B }
		\dd{ \hm^{ d -1 } }
	-
	\sum_{ 1 \leq k < l \leq P }
		\abs{ \sigma_{ i , k } - \sigma_{ i , l } }
		\int_{ \Sigma_{ k, l } }
			\rho_{ B }
		\dd{ \hm^{ d - 1 } }
	\\
	={} &
	\sum_{ \substack{1 \leq k < l \leq P \\ \{ k, l \} \neq \{ i, j \} } }
		\left(
			\sigma_{ k , l } - \abs{ \sigma_{ i , k } - \sigma_{ i , l } }
		\right)
		\int_{ \Sigma_{ k , l } }
			\rho_{ B }
		\dd{ \hm^{ d - 1 } }
	\\
	\lesssim{} &
	\sum_{ k \notin \{ i, j \} }
		\int
			\rho_{ B }
		\abs{ \nabla \chi_{ k } }.
\end{align*}
Thus we can estimate the error by the last summand of the error in 
\Cref{localization_lemma_with_normals}.
\end{remark}
\subsection{Convergence of the curvature term}

\begin{proposition}
	\label{convergence_of_curvature_multiphase}
	In the situation of \Cref{initial_convergence_result_multiphase} and under the energy convergence assumption (\ref{energy_convergence}), we have that the first variations converge in the sense that for almost every time $ 0 \leq t \leq T $, we have
	\begin{equation*}
		\lim_{ \varepsilon \to 0 }
			\int
				\inner*{ 
					\Delta u_{ \varepsilon } - \frac{ 1 }{ \varepsilon } \partial_{ u } W ( u_{ \varepsilon } ) 
				}
				{ \inner*{ \xi }{ \nabla u_{ \varepsilon } } }
			\dd{ x }
		=
		\sum_{ 1 \leq i < j \leq P }
			\sigma_{ i , j }
			\int_{ \Sigma_{ i , j } }
				\inner*{ \diff \xi }{ \mathrm{Id} - \nu_{ i } \otimes \nu_{ i } }
			\dd{ \hm^{ d - 1} }
	\end{equation*}
	and additionally we have the estimate
	\begin{equation}
		\label{pointwise_estimate_for_curvature}
		\int
		\inner*{ 
			\varepsilon \nabla u_{ \varepsilon } - \frac{ 1 }{ \varepsilon } 	\partial_{ u } W ( u_{ \varepsilon } ) 
		}
		{ \inner*{ \xi }{ \nabla u_{ \varepsilon } } }
		\dd{ x }
		\lesssim
		\norm{ \nabla \xi }_{ \sup }
		\energy_{ \varepsilon } ( u_{ \varepsilon } ).
	\end{equation}
\end{proposition}

\begin{remark}
	We can not proceed exactly as in the twophase case since we do not have one primitive $ \phi $ and more importantly, we can not expect the functions $ \psi_{ i }^{ \varepsilon } $ to satisfy 
	\begin{equation}
		\label{energy_convergence_of_psi_i}
		\abs{ \psi_{ i }^{ \varepsilon } } ( \flattorus ) \to \abs{ \psi_{ i } } ( \flattorus ),
	\end{equation}
	so the original theorem from Reshetnyak will not work here. However we have by the lower semicontinuity of the variation measure under the assumption of energy convergence (\ref{energy_convergence}) that
	\begin{align*}
		\abs{ \nabla \psi_{ i } } ( \flattorus )
		&
		\leq
		\liminf_{ \varepsilon \to 0 }
			\abs{ \nabla \psi_{ i }^{ \varepsilon } } ( \flattorus )
		\\
		& \leq
		\liminf_{ \varepsilon \to 0 }
			\energy_{ \varepsilon } ( u_{ \varepsilon } )
		\\
		& =
		\energy ( u )
		\\
		& =
		\sum_{ 1 \leq j < k \leq P }
			\sigma_{ j , k }
			\hm^{ d -1 } ( \Sigma_{ j , k } ).
	\end{align*}
	But by \Cref{rewriting_variation_of_psi_i}, we know that
	\begin{equation*}
		\abs{ \nabla \psi_{ i } }
		=
		\sum_{ 1 \leq j < k \leq P }
			\abs{ \sigma_{ i , j } - \sigma_{ i , k } }
			\hm^{ d - 1 } |_{ \Sigma_{ j , k } },
	\end{equation*}
	which yields that localized on $ \partial_{ \ast } \Omega_{ i } $, we have 
	the necessary convergence $ \abs{ \nabla \psi_{i }^{ \varepsilon } } \to 
	\abs{ \nabla \psi_{ i } } $. Thus we will develop a quantitative version of 
	Reshetnyaks theorem and apply it to our setting.
\end{remark}

\begin{proof}[Proof of \Cref{convergence_of_curvature_multiphase}.]
	Using the same calculations as in the twophase case, we obtain that
	\begin{align*}
		& \lim_{ \varepsilon \to 0 }
			\int
				\inner*{
					\varepsilon \Delta u_{ \varepsilon }
					-
					\frac{ 1 }{ \varepsilon } \partial_{ u } W ( u_{ \varepsilon } )
				}
				{
					\inner*{ \xi }{ \nabla u_{ \varepsilon } }
				}
			\dd{ x }
		\\
		={} &
		\lim_{ \varepsilon \to 0 }
			\int
				\varepsilon
				\left(
					\abs{ \nabla u_{ \varepsilon } }^{ 2 }
					\divg \xi 
					-
					\sum_{ i = 1 }^{ N }
						\sum_{ j, k = 1 }^{ d }
							\partial_{ x_{ j } } u_{ \varepsilon }^{ i }
							\partial_{ x_{ j } } \xi^{ k }
							\partial_{ x_{ k } } u_{ \varepsilon }^{ i }
				\right)
			\dd{ x } 
			\eqqcolon I
	\end{align*}
	Now however, we can not proceed as in the twophase case as explained above. 
	Instead we rewrite
	\begin{equation}
		\label{key_equality_for_ptw_estimate}
		I
		=
		\int
			\varepsilon
			\inner*{
				\diff \xi 
			}
			{
				\mathrm{Id} - N_{ \varepsilon }^{ \top } N_{ \varepsilon }
			}
			\abs{ \nabla u_{ \varepsilon } }^{ 2 }
		\dd{ x },
	\end{equation}
	where we define $ N_{ \varepsilon } \coloneqq \nabla u_{ \varepsilon } / \abs{ \nabla u_{ \varepsilon } } $. By the equipartition of energies \Cref{equipartition_of_energies_multiphase} and using that $ \abs{N_{ \varepsilon } } \leq 1 $, we can replace $ \varepsilon \abs{ \nabla u_{ \varepsilon } }^{ 2 } $ by $ \sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ \varepsilon  } } $. 
	
	Summarizing our results, it suffices by \Cref{equipartition_of_energies_multiphase} and rescaling to show for all $ A \in \cont^{ \infty } ( \flattorus ; \mathbb{ R }^{ d \times d } ) $ with $ \abs{ A } \leq 1 $ that
	\begin{equation}
		\label{desired_convergence_for_convergence_of_curvature}
		\lim_{ \varepsilon \to 0 }
			\int
				\inner*{ A }{ N_{ \varepsilon }^{ \top } N_{ \varepsilon } }
				\sqrt{ 2 W ( u_{ \varepsilon } ) }
				\abs{ \nabla u_{ \varepsilon } }
			\dd{ x }
		=
		\sum_{ 1 \leq i < j \leq P }
			\sigma_{ i , j }
			\int_{ \Sigma_{ i , j } }
				\inner*{ A }{ \nu_{ i } \otimes \nu_{ i } }
			\dd{ \hm^{ d - 1 } }.
	\end{equation}
	To this end, we will show the following three claims for a cutoff $ \eta $.
	\begin{itemize}[wide=0pt]
		\item[Claim 1:]
		We choose a majority phase by introducing the function $ \phi_{ i } $ on the right hand side of equation (\ref{desired_convergence_for_convergence_of_curvature}). The corresponding error is given by
		\begin{equation*}
			\limsup_{ \varepsilon \to 0 }
				\abs{ 
					\int
						\eta 
						\inner*{ A }{ N_{ \varepsilon }^{ \top } N_{ \varepsilon } }
						\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ \varepsilon } } 
					\dd{ x }
					-
					\int
						\eta
						\inner*{ A }{ \nu_{ i }^{ \varepsilon } \otimes \nu_{ i }^{ \varepsilon } }
						\abs{ \nabla \psi_{ i } }
					\dd{ x }
				}
			\lesssim
				\energy ( u ; \eta ) 
				-
				\int
					\eta
				\abs{ \nabla \psi_{ i } },
		\end{equation*}
		where the approximate normal of the $ i$-th phase is defined by $ \nu_{ i }^{ \varepsilon } \coloneqq \nabla \psi_{ i }^{ \varepsilon } / \abs{ \nabla \psi_{ i }^{ \varepsilon } } $.
		
		\item[Claim 2:]
		By a quantitative Reshetnyak type argument, we have
		\begin{equation*}
			\limsup_{ \varepsilon \to 0 }
				\abs{
					\int
						\eta \inner*{ A }{ \nu_{ i }^{ \varepsilon } \otimes \nu_{ i }^{ \varepsilon } }
						\abs{ \nabla \psi_{ i }^{ \varepsilon } }
					\dd{ x }
					-
					\int
						\eta \inner*{ A }{ \theta_{ i }  \otimes 
						\theta_{ i } }
					\abs{ \nabla \psi_{ i } }
				}
			\lesssim
				\energy ( u ; \eta ) - \int \eta \abs{ \nabla \psi_{ i } },
		\end{equation*}
		where $ \theta_{ i } \coloneqq \nabla \psi_{ i } / \abs{ \nabla \psi_{ 
		i } } $.
		\item[Claim 3:] 
		We can undo the localization onto the majority phase. The corresponding error is given by
		\begin{equation*}
			\abs{ 
				\int
					\eta
					\inner*{ A }{ \theta_{ i } \otimes \theta_{ i } }
				\abs{ \nabla \psi_{ i } }
				-
				\sum_{ 1 \leq j < k \leq P }
					\sigma_{ j , k }
					\int_{ \Sigma_{ j , k } }
						\eta 
						\inner*{ A }{ \nu_{ j } \otimes \nu_{ j } }
					\dd{ \hm^{ d - 1 } }
			}
		\leq
		\energy ( u ; \eta ) - \int \eta \abs{ \nabla \psi_{ i } },
		\end{equation*}
		where we remind that $ \nu_{ j } $ is the inner unit normal of $ 
		\Omega_{ i } $.
	\end{itemize}
	Let us first assume that we have proven those three claims and show how the desired convergence (\ref{desired_convergence_for_convergence_of_curvature}) follows from them. 
	We take a partition of unity $ \eta_{ B } $ of the flat torus with respect 
	to the covering $ \mathcal{ B }_{ r } $ introduced in 
	\Cref{section_localization_estimates}. Then
	\begin{align*}
		& \limsup_{ \varepsilon \to 0 }
			\abs{
				\int
					\inner*{ A }{ N_{ \varepsilon }^{ \top } N_{ \varepsilon } }
					\sqrt{ 2 W ( u_{ \varepsilon } ) }
					\abs{ \nabla u_{ \varepsilon } }
				\dd{ x }
				-
				\sum_{ 1 \leq j < k \leq P }
					\sigma_{ j , k }
				 	\int_{ \Sigma_{ j , k } }
				 		\inner*{ A }{ \nu_{ j } \otimes \nu_{ j } }
				 	\dd{ \hm^{ d - 1 } }
			} 
		\\
		={} &
		\abs{ 
			\sum_{ B \in \mathcal{ B }_{ r } }
				\int
					\inner*{ A \eta_{ B } }
					{ N_{ \varepsilon }^{ \top } N_{ \varepsilon } }
					\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ \varepsilon } }
				\dd{ x }
			-
			\sum_{ 1 \leq j < k \leq P }
				\sigma_{ j , k }
				\int_{ \Sigma_{ j , k } }
					\inner*{ A \eta_{ B } }
					{ \nu_{ i } \otimes \nu_{i } }
				\dd{ \hm^{ d - 1 } }
		}
		\\
		\leq{} &
		\sum_{ B \in \mathcal{ B }_{ r } }
			\min_{ 1 \leq i \leq P }
				\abs{ 
					\int
						\inner{ A \eta_{ B } }{ N_{ \varepsilon }^{ \top } N_{ \varepsilon } }
						\sqrt{ 2 W ( u_{ \varepsilon } ) }
						\abs{ \nabla u_{ \varepsilon } }
					\dd{ x }
					-
					\int
						\inner*{ A \eta_{ B } }
						{ \nu_{ i }^{ \varepsilon } \otimes \nu_{ i }^{ 
						\varepsilon } }
						\abs{ \nabla \psi_{ i }^{ \varepsilon } }
					\dd{ x }
				}
			\\
			& \quad \quad \quad \;\;\;\!\:+
			\abs{ 
				\int
					\inner*{ A \eta_{ B } }{ \nu_{ i }^{ \varepsilon } \otimes \nu_{ i }^{ \varepsilon } }
					\abs{ \nabla \psi_{ i }^{ \varepsilon } }
				\dd{ x }
				-
				\int
					\inner*{ A \eta_{ B } }
					{ \theta_{ i } \otimes \theta_{ i } }
				\abs{ \nabla \psi_{ i } }
			}
			\\
			& \quad \quad \quad \;\;\;\!\: +
			\abs{ 
				\int
					\inner*{ A \eta_{ B } }
					{ \theta_{ i } \otimes \theta_{ i } }
				\abs{ \nabla \psi_{ i } }
				-
				\sum_{ 1 \leq j < k \leq P }
					\sigma_{ j , k }
					\int_{ \Sigma_{ j , k } }
						\inner*{ A \eta_{ B } }
						{ \nu_{ j } \otimes \nu_{ j } }
					\dd{ \hm^{ d - 1 } }
			}
		\\
		\lesssim {} &
			\sum_{ B \in \mathcal{ B }_{ r } }
				\min_{ 1 \leq i \leq P }
					\energy ( u ; \eta_{ B } )
					-
					\int
						\eta_{ B }
					\abs{ \nabla \psi_{ i } },
	\end{align*}
	which vanishes as $ r $ tends to zero by 
	\Cref{localization_estimate_weaker}.
	Thus let us now prove the three claims.
	
	\begin{proof}[Proof of Claim 1.]
		For simplicity, we drop the index $ i $ and for now also $ \varepsilon 
		$.
		First, we replace the matrix $ N $ by the matrix $ \pi N $, where we 
		define the rank-one matrix $ \pi $ by
		\begin{equation*}
			\pi 
			\coloneqq
			\frac{ \partial_{ u } \phi }{ \abs{ \partial_{ u } \phi } }
			\otimes
			\frac{ \partial_{ u } \phi }{ \abs{ \partial_{ u } \phi } }
			\in 
			\mathbb{ R }^{ N }.
		\end{equation*}
		The multiplication with $ \pi $ is an orthogonal projection $ \pi 
		\colon \mathbb{ R }^{ N \times d } \to \mathbb{ R }^{ N \times d } $. 
		Moreover, we can compute that
		\begin{align*}
			( \pi N^{ \top } \pi N )_{ i j }
			& =
			\sum_{ k = 1 }^{ N }
				( \pi N )_{ k i }
				( \pi N )_{ k j }
			=
			\sum_{ k = 1 }^{ N }
				\left(
					\sum_{ l = 1 }^{ N }
						\pi_{ k l } N_{ l i }
				\right)
				\left(
					\sum_{ r = 1 }^{ N }
						\pi_{ k r } N_{ r j }
				\right)
			\\
			& =
			\sum_{ l, r = 1 }^{ N }
				N_{ l i } N_{ r , j }
				\sum_{ k = 1 }^{ N }
					\pi_{ k l }
					\pi_{ k r }
			=
			\sum_{ l, r = 1 }^{ N }
				N_{ l i }N_{ r j }
				\sum_{ k = 1 }^{ N }
					\frac{ \partial_{ k } \phi  \partial_{ l } \phi \partial_{ 
					k } \phi \partial_{ r } \phi }{ \abs{ \partial_{ u } \phi 
					}^{ 4 } }
			\\
			& =
			\sum_{ l, r = 1 }^{ N }
				N_{ l i } \frac{ \partial_{ l } \phi }{ \abs{ \partial_{ u } 
				\phi } }
				N_{ r j } \frac{ \partial_{ r } \phi }{ \abs{ \partial_{ u } 
				\phi } }
			=
			\frac{ \partial_{ i } \psi }{ \abs{ \nabla u } \abs{ \partial_{ u } 
			\phi } }
			\frac{ \partial_{ j } \psi }{ \abs{ \nabla u } \abs{ \partial_{ u } 
			\phi } }
		\end{align*}
		Thus we infer that
		\begin{align*}
			\inner*{ A }{ \pi N_{ \varepsilon }^{ \top } \pi N_{ \varepsilon } }
			& =
			\sum_{ i, j = 1 }^{ d }
				A_{ i , j } 
				\frac{ \partial_{ i } \psi_{ \varepsilon } }{ \abs{ \nabla \phi 
				} \abs{ \nabla u_{ \varepsilon } } }
				\frac{ \partial_{ j } \psi_{ \varepsilon } }{ \abs{ \nabla \phi 
				} \abs{ \nabla u_{ \varepsilon } } }
			\\
			& =
			\frac{ \abs{ \nabla \psi_{ \varepsilon } }^{ 2 } }{ \abs{ \nabla 
			\phi }^{ 2 } \abs{ \nabla u_{ \varepsilon } }^{ 2 } }
			\inner*{ A }
			{ \frac{ \nabla \psi^{ \varepsilon } }{ \abs{ \nabla \psi^{ 
			\varepsilon } } } \otimes \frac{ \nabla \psi^{ \varepsilon } }{ 
			\abs{ \nabla \psi^{ \varepsilon } } } }
			= 
			\abs{ \pi N_{ \varepsilon } }^{ 2 }
			\inner*{ A }{ \nu^{ \varepsilon } \otimes \nu^{ \varepsilon } },
		\end{align*}
		where we used that 
		\begin{equation*}
			\abs{ \pi N_{ \varepsilon } }^{ 2 }
			=
			\frac{ \abs{ \nabla \psi_{ \varepsilon } }^{ 2 } }{ \abs{ \nabla 
			\phi }^{ 2 } \abs{ \nabla u_{ \varepsilon } }^{ 2 } }.
		\end{equation*}
		Moreover we recognize that since multiplication with $ \pi $ is 
		an orthogonal projection, we have the Pythagorean Theorem
		\begin{align*}
			N^{ \top } N 
			& =
			( \pi N + N - \pi N )^{ \top } ( \pi N + N - \pi N )
			\\
			& =
			( \pi N )^{ \top } \pi N 
			+
			( N - \pi N )^{ \top } ( N - \pi N )
			+
			( \pi N )^{ \top } ( N - \pi N )
			+
			( N - \pi N )^{ \top } \pi N 
			\\
			& =
			( \pi N )^{ \top } \pi N
			+
			( N - \pi N )^{ \top } ( N - \pi N ).
		\end{align*}
		In order to prove the claim, we first get an error when replacing $ N_{ 
		\varepsilon }^{ \top } N_{ \varepsilon } $ with $ \nu^{ \varepsilon } 
		\otimes \nu^{ \varepsilon } $ and the second error when replacing $ 
		\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ \varepsilon } } $ 
		by $ \abs{ \nabla \psi_{ \varepsilon } } $.
		For the first error we can estimate
		\begin{align*}
			& \abs{ 
				\int
					\eta 
					\inner*{ A }{ N_{ \varepsilon } N_{ \varepsilon }^{ \top } }
					\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ 
					\varepsilon } }
				\dd{ x }
				-
				\int
					\eta
					\inner*{ A }{ \nu^{ \varepsilon } \otimes \nu^{ \varepsilon 
					} }
					\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ 
					\varepsilon } }
				dd{ x }
			}
			\\
			\leq{} &
			\abs{ 
				\int
					\eta 
					\inner*{ A }{ N_{ \varepsilon }^{ \top } N_{ \varepsilon } }
					\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ 
					\varepsilon } } 
				\dd{ x }
				-
				\int 
					\eta
					\inner*{ A }
					{ \pi N_{ \varepsilon }^{ \top } \pi N_{ \varepsilon } }
					\sqrt{ 2 W ( u_{ \varepsilon } ) }
					\abs{ \nabla u_{ \varepsilon } }
				\dd{ x }
			}
			\\
			& + 
			\abs{ 
				\int
					\eta
					\inner*{ A }
					{ \pi N_{ \varepsilon }^{ \top } \pi N_{ \varepsilon } }
					\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ 
					\varepsilon } }
				\dd{ x }
				-
				\int
					\eta
					\inner*{ A }
					{ \nu^{ \varepsilon } \otimes \nu^{ \varepsilon } }
					\sqrt{ 2 W ( u_{ \varepsilon } ) }
					\abs{ \nabla u_{ \varepsilon } }
				\dd{ x }
			}
			\\
			\leq{} & 
			\int
				\eta
				\abs{ N_{ \varepsilon } - \pi N_{ \varepsilon } }^{ 2 }
				\sqrt{ 2 W ( u_{ \varepsilon} ) } \abs{ \nabla u_{ \varepsilon 
				} }
			\dd{ x }
			+
			\int
				\eta
				\left( 
					1 - \abs{ \pi N_{ \varepsilon } }
				\right)^{ 2 }
				\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ \varepsilon 
				} }
			\dd{ x }= I_{ \varepsilon }.
		\end{align*}
		Using again that multiplication with $ \pi $ is an orthogonal 
		projection, we have
		\begin{align*}
			\abs{
				( \mathrm{Id} - \pi ) N_{ \varepsilon }
			}^{ 2 }
			& =
			\abs{ N_{ \varepsilon } }^{ 2 } 
			-
			\abs{ \pi N_{ \varepsilon } }^{ 2 }
			=
			1 - \abs{ \pi N_{ \varepsilon } }^{ 2 }
			\lesssim
			1 - \abs{ \pi N_{ \varepsilon } }
			=
			1 -
			\abs{ \frac{ \diff \phi }{ \abs{ \nabla \phi } } N_{ \varepsilon } 
			},
		\end{align*}
		where for the last identity, we used that $ \abs{ v^{ \top } B } = 
		\abs{ v \otimes v B } $ for all unit vectors $ v $ and matrices $ B $.
		Therefore we can estimate
		\begin{align*}
			I_{ \varepsilon }
			& \lesssim
			\int
				\eta
				\left(
					1 - \abs{ \frac{ \diff \phi }{ \abs{ \nabla \phi } } N_{ 
					\varepsilon } }
				\right)
				\sqrt{ 2 W ( u_{ \varepsilon } ) }
				\abs{ \nabla u_{ \varepsilon } }
			\dd{ x }
			\\
			& =
			\int
				\eta 
				\left(
					\sqrt{ 2 W ( u_{ \varepsilon } ) }
					\abs{ \nabla u_{ \varepsilon } }
					-
					\abs{ \nabla \psi^{ \varepsilon } }
					\frac{ \sqrt{ 2 W ( u_{ \varepsilon } ) } }{ \abs{ \nabla 
					\phi ( u_{ \varepsilon } ) } }
				\right)
			\dd{ x }
			\\
			& \leq
			\energy_{ \varepsilon } ( u_{ \varepsilon } ; \eta )
			-
			\int
				\eta
				\abs{ \nabla \psi^{ \varepsilon } }
			\dd{ x }.
		\end{align*}
		The last inequality is due to Young's inequality and $ \abs{ \nabla 
		\phi } \leq \sqrt{ 2 W ( u_{ \varepsilon } ) } $.
		By the convergence of energies for almost every time and the lower 
		semicontinuity of the variation measure, we thus have
		\begin{equation*}
			\limsup_{ \varepsilon \to 0 }
				I_{ \varepsilon }
			\lesssim
			\energy ( u ; \eta )
			-
			\int
				\eta
			\abs{ \nabla \psi }.
		\end{equation*}
		The second error is given by
		\begin{align*}
			& \abs{
				\int
					\eta
					\inner*{ A }{ \nu^{ \varepsilon } \otimes \nu^{ \varepsilon 
					} }
					\sqrt{ 2 W ( u_{ \varepsilon } ) }
					\abs{ \nabla u_{ \varepsilon } }
				\dd{ x }
				-
				\int
					\eta
					\inner*{ A }{ \nu^{ \varepsilon } \otimes \nu^{ \varepsilon 
					} }
					\abs{ \nabla \psi^{ \varepsilon } }
				\dd{ x }
			}
			\\
			={} &
			\abs{
				\int
					\eta
					\inner*{ A }{ \nu^{ \varepsilon } \otimes \nu^{ \varepsilon 
					} }
					\left(
						\sqrt{ 2 W ( u_{ \varepsilon } ) } \abs{ \nabla u_{ 
						\varepsilon } } 
						-
						\abs{ \nabla \psi^{ \varepsilon } }
					\right)
				\dd{ x }
			}
			\\
			\leq {} &
			\int
				\eta
				\left(
					\sqrt{ 2 W ( u_{ \varepsilon } ) }
					\abs{ \nabla u_{ \varepsilon } }
					-
					\abs{ \nabla \psi^{ \varepsilon } }
				\right)
			\dd{ x }
			\\
			\leq{} &
			\energy_{ \varepsilon } ( u_{ \varepsilon } ; \eta )
			-
			\int
				\eta 
				\abs{ \nabla \psi^{ \varepsilon } }
			\dd{ x },
		\end{align*}
		which in the limes superior can be controlled by the desired term as 
		above, finishing the proof for the first claim.
	\end{proof}
	
	\begin{proof}[Proof of Claim 2.]
		Consider the sequence $ ( \mu_{ \varepsilon } )_{ \varepsilon } $ of 
		Radon measures on $ \flattorus \times \mathbb{ S }^{ d - 1 } $ defined 
		by 
		\begin{equation*}
			\mu_{ \varepsilon }
			\coloneqq
			\delta_{ u_{ \varepsilon } ( x ) }
			\abs{ \nabla \psi^{ \varepsilon } } \dd{ x }
		\end{equation*}
		which acts on continuous functions $ \varphi $ through
		\begin{equation*}
			\int_{ \flattorus \times \mathbb{ S }^{ d - 1 } }
				\varphi ( x , \nu )
			\dd{ \mu_{ \varepsilon } ( x , \nu ) }
			=
			\int_{ \flattorus }
				\varphi \left( x , \nu_{ \varepsilon } ( x ) \right) 
				\abs{ \nabla \psi^{ \varepsilon } }
			\dd{ x }.
		\end{equation*}
		By Young's inequality and the boundedness of energies, $ \mu_{ 
		\varepsilon } $ is a bounded sequence of Radon measures, thus we find a 
		Radon measure $ \tilde{ \mu } $ on $ \flattorus \times \mathbb{ S }^{ d 
		- 1 } $ and some non-relabelled subsequence such that $ \mu_{ 
		\varepsilon } \rightharpoonup^{ \ast } \tilde{ \mu } $ as Radon 
		measures on $ \flattorus \times \mathbb{ S }^{ d - 1 } $.
		By 
		\cite[Thm.~2.28]{ambrosio_fusco_pallara_functions_of_bv_and_free_discontinuity_problems}
		we can disintegrate the measure $ \tilde{ \mu } $, which means that we 
		find probability measures $ ( p_{ x } )_{ x \in \flattorus } $ and a 
		Radon measure $ \mu $ on $ \flattorus $ such that $ x \mapsto p_{ x } $ 
		is $ \mu $-measurable and we have the identity 
		\begin{equation*}
			\int_{ \flattorus \times \mathbb{ S }^{ d - 1 } }
				f ( x , \tilde{ \nu } )
			\dd{ \tilde{ \mu } ( x, \tilde{ \nu } ) }
			=
			\int_{ \flattorus }
				\int_{ \mathbb{ S }^{ d - 1 } }
					f ( x , \tilde{ \nu } )
				\dd{ p_{ x } ( \tilde{ \nu } ) }
			\dd{ \mu ( x ) }
		\end{equation*}
		for all $ f \in \lp^{ 1 } ( \flattorus \times \mathbb{ S }^{ d -1 } , 
		\tilde{ \mu } ) $.
		Thus we have
		\begin{equation*}
			\lim_{ \varepsilon \to 0 }
				\int
					\varphi ( x , \nu_{ \varepsilon } ) 
					\abs{ \nabla \psi^{ \varepsilon } }
				\dd{ x }
			=
			\int_{ \flattorus }
				\int_{ \mathbb{ S }^{ d - 1 } }
					\varphi ( x, \tilde{ \nu } )
				\dd{ p_{ x } ( \tilde{ \nu } ) }
			\dd{ \mu ( x ) }
		\end{equation*} 
		for all continuous $ \varphi $ and plugging in $ \varphi ( x , \tilde{ 
		\nu } ) \coloneqq \inner*{ A ( x ) }{ \tilde{ \nu } \otimes \tilde{ \nu 
		} } $ thus yields
		\begin{equation*}
			\lim_{ \varepsilon \to 0}
				\int
					\eta
					\inner*{ A }{ \nu^{ \varepsilon } \otimes \nu^{ \varepsilon 
					} }
					\abs{ \nabla \psi^{ \varepsilon } }
				\dd{ x }
			=
			\int
				\eta
				\inner*{ A ( x ) }
				{
					\int
						\tilde{ \nu } \otimes \tilde{ \nu }
					\dd{ p_{ x } ( \tilde{ \nu } ) }
				}
			\dd{ \mu ( x ) }.
		\end{equation*}
		We now would like to prove that up to an error bounded by $ \energy ( u 
		; \eta ) - \int \eta \abs{ \nabla \psi } $, the right-hand side is 
		equal to $ \int \inner*{ A }{ \theta \otimes \theta } \abs{ \nabla \psi 
		} $.
		
		On the one hand, we have by the lower semicontinuity of the variation 
		measure that
		\begin{equation}
			\label{mu_doominates_variation_of_psi}
			\int
				\eta
			\abs{ \nabla \psi }
			\leq
			\liminf_{ \varepsilon \to 0 }
				\int
					\eta
					\abs{ \nabla \psi^{ \varepsilon } }
				\dd{ x }
			=
			\int
				\eta ( x )
				\int
					1
				\dd{ p_{ x } ( \tilde{ \nu } ) }
			\dd{ \mu ( x ) }
			=
			\int
				\eta ( x ) 
			\dd{ \mu ( x ) },
		\end{equation}
		or in other words, we have $ \abs{ \nabla \psi } \leq \mu $.
		
		On the other hand we have by the convergence of the energies and 
		Young's inequality that we 
		may estimate $ \mu $ via 
		\begin{equation}
			\label{mu_is_dominated_by_energy}
			\int
				\eta
			\dd{ \mu }
			=
			\lim_{ \varepsilon \to 0 }
				\int
					\eta
					\abs{ \nabla \psi^{ \varepsilon } }
				\dd{ x }
			=
			\liminf_{ \varepsilon \to 0 }
				\energy_{ \varepsilon } ( u_{ \varepsilon } ; \eta )
			=
			\energy ( u ; \eta ).
		\end{equation}
		Using that
		\begin{equation*} 
			\abs{ \tilde{ \nu } \otimes \tilde{ \nu } - \theta \otimes \theta } 
			= 
			\abs{ 
				\tilde{ \nu } \otimes ( \tilde{ \nu } - \theta ) 
				+
				\theta \otimes ( \tilde{ \nu } - \theta ) 
			}
			\leq
			2 \abs{ \tilde{ \nu } - \theta }
		\end{equation*}
		and inequality (\ref{mu_doominates_variation_of_psi}), we can therefore 
		estimate
		\begin{align*}
			&
			\abs{ 
				\int
					\int_{ \mathbb{ S }^{ d - 1 } }
						\eta
						\inner*{ A }{ \tilde{ \nu } \otimes \tilde{ \nu } }
					\dd{ p_{ x } ( \tilde{ \nu } ) }
				\dd{ \mu }
				-
				\int
					\eta
					\inner*{ A }{ \theta \otimes \theta }
				\abs{ \nabla \psi }
			}
			\\
			\leq{} &
			\abs{ 
				\int
					\eta 
					\inner*{ A }
					{ 
						\int_{ \mathbb{ S }^{ d - 1 } }
							\tilde{ \nu } \otimes \tilde{ \nu }
						\dd{ p_{ x } ( \tilde{ \nu } ) }
					}
				( \dd{ \mu } - \abs{ \nabla \psi } )
			}
			+
			\abs{
				\int
					\eta
					\inner*{ A }{
						\int_{ \mathbb{ S }^{ d - 1 } }
							\tilde{ \nu } \otimes \tilde{ \nu }
							-
							\theta \otimes \theta
						\dd{ p_{ x } ( \tilde{ \nu } ) }
					}
				\abs{ \nabla \psi }
			}
			\\
			\leq {} &
			\int
				\eta
			\left( \dd{ \mu } - \abs{ \nabla \psi } \right)
			+
			2
			\int
				\eta
				\int_{ \mathbb{ S }^{ d - 1 } }
					\abs{ \tilde{ \nu } - \theta } 
				\dd{ p_{ x } ( \tilde{ \nu } ) }
			\abs{ \nabla \psi }.
		\end{align*}
		The first summand can by inequality (\ref{mu_is_dominated_by_energy}) 
		be estimated by 
		$ \energy ( u ; \eta ) - \int \eta \abs{ \nabla \psi } $.
		For the second summand, we use a duality argument:
		Given a smooth vectorfield $ \xi $, we have by the weak convergence $ 
		\nabla \psi_{ \varepsilon } \to \nabla \psi $ that
		\begin{equation*}
			\int
				\inner*{ \xi }{ \theta }
			\abs{ \nabla \psi }
			=
			\lim_{ \varepsilon \to 0 }
				\int
					\inner*{ \xi }{ \nu^{ \varepsilon } }
					\abs{ \nabla \psi^{ \varepsilon } }
				\dd{ x }
			=
			\int
				\inner*{ \xi }{
					\int 
						\tilde{ \nu } 
					\dd{ p_{ x } ( \tilde{ \nu } ) } 
				}
			\dd{ \mu },
		\end{equation*}
		from which we deduce that
		\begin{align*}
			\int
				\inner*{ \xi }{
					\int
						\theta - \tilde{ \nu }
					\dd{ p_{ x } ( \tilde{ \nu } ) }
				}
			\abs{ \nabla \psi }
			& =
			\int
				\inner*{ \xi }{
					\int
						\tilde{ \nu }
					\dd{ p_{ x } ( \tilde{ \nu } ) }
				}
			\left(
				\dd{ \mu } - \abs{ \nabla \psi }
			\right)
			\\
			& \leq
			\int
				\abs{ \xi }
			\left(
				\dd{ \mu } - \abs{ \nabla \psi }
			\right)
			\\
			& \leq
			\energy ( u ; \abs{ \xi } )
			-
			\int
				\abs{ \xi }
			\abs{ \nabla \psi },
		\end{align*}
		which finishes the proof.
	\end{proof}

	\begin{proof}[Proof of Claim 3.]
		First we notice that since $ \psi_{ i } = \sum_{ j } \sigma_{ i , j } 
		\mathds{ 1 }_{ \Omega_{ j } } $, we have $ \theta_{ i } = \pm \nu_{ j } 
		$ on $ \Sigma_{ j , k } $ $ \abs{ \nabla \psi_{ i } }$ almost 
		everywhere.
		Additionally using the representation of $ \abs{ \nabla \psi_{ i } } $ 
		given in 
		\Cref{rewriting_variation_of_psi_i}, we thus have
		\begin{align*}
			&
			\abs{
				\int
					\eta 
					\inner*{ A }
					{ \theta_{ i } \otimes \theta_{ i } }
				\abs{ \nabla \psi_{ i } }
				-
				\sum_{ 1 \leq j < k \leq P }
					\sigma_{ j , k }
					\int_{ \Sigma_{ j , k } }
						\eta
						\inner*{ A }{ \nu_{ j } \otimes \nu_{ j } }
					\dd{ \hm^{ d - 1 } }
			}
			\\
			={} &
			\abs{ 
				\sum_{ 1 \leq j < k \leq P }
					\left( 
						\abs{ \sigma_{ i , j } - \sigma_{ i , k } }
						-
						\sigma_{ j , k }
					\right)
					\int_{ \Sigma_{ j k  } }
						\eta
						\inner*{ A }{ \nu_{ j } \otimes \nu_{ j } }
					\dd{ \hm^{ d - 1 } }
			}
			\\
			\leq{} &
			\sum_{ 1 \leq j < k \leq P }
				\int_{ \Sigma_{ j , k } }
					\eta
					\left(
						\sigma_{ j , k } - \abs{ \sigma_{ i , j } - \sigma_{ i 
						, k } }
					\right)
				\dd{ \hm^{ d - 1 } }
			\\
			={} &
			\energy ( u ; \eta )
			-
			\int
				\eta
			\abs{ \nabla \psi_{ i } },
		\end{align*}
		where for the inequality, we used that by the triangle inequality for 
		the surface tensions, we have
		$ \abs{ \sigma_{ i , j } - \sigma_{ i , k } } \leq \sigma_{ j , k } $.
	\end{proof}
	This finishes the proofs for the three claims. Lastly we notice that we 
	obtain the pointwise in time bound (\ref{pointwise_estimate_for_curvature}) 
	from the rewritten term (\ref{key_equality_for_ptw_estimate}).
\end{proof}

\subsection{Convergence of the velocity term}

As in the previous proof for the convergence of the curvature term we want to 
localize and argue as in the twophase case. Moreover we remember from the 
twophase case that we had to freeze the unit normal. However we now have the 
important difference that $ \nabla u_{ \varepsilon } $ describes both the 
change in physical space (domain) and the state space (codomain). Since the 
supposed limit $ \nu_{ i } $ only describes the change in physical space, we 
should only freeze the normal in this direction. Using the equipartition of 
energies \Cref{equipartition_of_energies_multiphase} which tells us that $ 
\varepsilon / 2 \abs{ \nabla u_{ \varepsilon } }^{ 2 } $ roughly equals $ 1 / 
\varepsilon W ( u_{ \varepsilon } ) $, we come up with the following definition 
which is similar to the tilt-excess defined in the twophase case.

\begin{definition}
	Let $ \nu^{ \ast } \in \mathbb{ S }^{ d - 1 } $ and $ \eta \in \cont^{ 
	\infty } \left( [ 0 , T ] \times \flattorus ; [ 0 , 1 ] \right) $. For $ 
	\varepsilon > 0 $ and a function $ u_{ \varepsilon } \in \wkp^{ 1 , 2 } 
	\left( ( 0 , T ) \times \flattorus ; \mathbb{ R }^{ N } \right) $, the 
	approximative localized tilt-excess of the $ i$-th phase is given by by
	\begin{equation*}
		\tilt_excess_{ i }^{ \varepsilon } ( \nu^{ \ast } ; \eta , u_{ 
		\varepsilon } )
		\coloneqq
		\int_{ 0 }^{ T }
			\int
				\eta
				\frac{ 1 }{ \varepsilon }
				\abs{ 
					\varepsilon \nabla u_{ \varepsilon } 
					+
					\nabla \phi_{ i } ( u_{ \varepsilon } ) 
					\otimes
					\nu^{ \ast }
				}^{ 2 }
			\dd{ x }
		\dd{ t }.
	\end{equation*}
	In the limit $ \varepsilon = 0 $ and for a partition 
	$ \chi_{ i } = \mathds{ 1 }_{ \Omega_{ i } } \in \bv \left(
		( 0 , T ) \times \flattorus ; \{ 0 , 1 \} 
	\right) $
	with $ \sum_{ i } \chi_{ i } = 1 $,
	we define the tilt-excess for $ 1 \leq i, j \leq P $ , $ i \neq j $ to be
	\begin{equation*}
		\tilt_excess_{ i j } ( \nu^{ \ast } ; \eta , u ) 
		\coloneqq
		\int_{ 0 }^{ T }
			\int
				\eta
				\abs{ \nu_{ i } - \nu^{ \ast } }^{ 2 }
			\abs{ \nabla \chi_{ i } }
		\dd{ t }
		+
		\int_{ 0 }^{ T }
			\int
				\eta
				\abs{ \nu_{ j } + \nu^{ \ast } }^{ 2 }
			\abs{ \nabla \chi_{ j } }
		\dd{ t }
		+
		\sum_{ k \in \{ i , j \} }
			\int_{ 0 }^{ T }
				\int
					\eta 
				\abs{ \nabla \chi_{ k } }
			\dd{ t },
	\end{equation*}
	where $ u = \sum_{ 1 \leq i \leq P } \chi_{ i } \alpha_{ i } $.
\end{definition}

Notice that we use $ + \nabla \phi_{ i } ( u_{ \varepsilon } ) \otimes \nu^{ 
\ast } $ in the definition of the approximative tilt excess instead of its 
negative since the normal of $ \chi_{ i } $ points inwards with respect to $ 
\Omega_{ i } $, but $ \nabla \phi_{ i } / \abs{ \nabla \phi_{ i } } $ points 
away from $ \Omega_{ i } $.

Moreover we want to point out that the first two summands of the tilt-excess $ 
\tilt_excess_{ i , j } $ measure the local flatness of the boundary, and the 
last summand measure if mostly the $(i,j)$-th phase is present, see also the 
discussion in \Cref{section_localization_estimates}.

As in the twophase case, we first want to argue that when $ \varepsilon $ 
approaches zero, the approximate tilt-excess can be bounded by the tilt-excess 
of the limit.

\begin{lemma}
	\label{approximate_tilt_excess_estimated_in_limit_by_tilt_excess}
	Assume that we are in the situation of 
	\Cref{initial_convergence_result_multiphase} and that the time-integrated 
	energies converge (\ref{energy_convergence}). Then for every $ 1 \leq i , j 
	\leq P $ with $ i \neq j $, every unit vector $ \nu^{ \ast } \in \mathbb{ S 
	}^{ d - 1 } $ and 
	$ \eta \in \cont^{ \infty } \left( [ 0 , T ] \times \flattorus ; [ 0 ,1 ] 
	\right) $, we have
	\begin{equation*}
		\limsup_{ \varepsilon \to 0 }
			\tilt_excess_{ i }^{ \varepsilon } ( \nu^{ \ast } ; \eta , u_{ 
			\varepsilon } ) 
			\lesssim
			\tilt_excess_{ i j } ( \nu^{ \ast } ; \eta , \chi ).
	\end{equation*}
\end{lemma}

\begin{proof}
	By expanding the square, we see that we can rewrite the approximate 
	tilt-excess as
	\begin{align*}
		& \tilt_excess_{ i }^{ \varepsilon } ( \nu^{ \ast } ; \eta , u_{ 
		\varepsilon } ) 
		\\
		={} &
		\int_{ 0 }^{ T }
			\int
				\eta
				\frac{ 1 }{ \varepsilon }
				\left(
					\varepsilon^{ 2 }
					\abs{ \nabla u_{ \varepsilon } }^{ 2 }
					+
					2 \varepsilon 
					\inner*{ \nabla u_{ \varepsilon } }
					{ \nabla \phi_{ i } ( u_{ \varepsilon } ) \otimes \nu^{ 
					\ast } }
					+
					\abs{ \nabla \phi_{ i } ( u_{ \varepsilon } ) \otimes \nu^{ 
					\ast } }^{ 2 }
				\right)
			\dd{ x }
		\dd{ t }
		\\
		\eqqcolon {} &
		A_{ \varepsilon } + B_{ \varepsilon } + C_{ \varepsilon}.
	\end{align*}
	Using the equipartition of energies 
	\Cref{equipartition_of_energies_multiphase}, we immediately get that 
	\begin{align*}
		\limsup_{ \varepsilon \to 0 }
			A_{ \varepsilon }
		& =
		\int_{ 0 }^{ T }
			\energy ( u ; \eta )
		\dd{ t }
		\shortintertext{and}
		\limsup_{ \varepsilon \to 0 }
			C_{ \varepsilon }
		& \leq
		\limsup_{ \varepsilon \to 0 }
			\int_{ 0 }^{ T }
				\int
					\eta
					\frac{ 1 }{ \varepsilon }
					\abs{ \nabla \phi_{ i } ( u_{ \varepsilon } ) }^{ 2 }
				\dd{ x }
			\dd{ t }
		\\
		& \leq
		\limsup_{ \varepsilon \to 0 }
		\int_{ 0 }^{ T }
			\int
				\eta
				\frac{ 1 }{ \varepsilon }
				2 W ( u_{ \varepsilon } ) 
			\dd{ x }
		\dd{ t }
		\\
		& =
		\int_{ 0 }^{ T }
			\energy ( u ; \eta )
		\dd{ t }.
	\end{align*}
	For the remaining summand, we note that
	\begin{equation*}
		\limsup_{ \varepsilon \to 0 }
			B_{ \varepsilon }
		=
		\limsup_{ \varepsilon \to 0 }
			\int_{ 0 }^{ T }
				\int
					2 \eta
					\inner*{ \nabla \psi_{ i }^{ \varepsilon } }{ \nu^{ \ast } }
				\dd{ x }
			\dd{ t }
		=
		2 \int_{ 0 }^{ T }
			\int
				\eta
				\inner*{ \nu^{ \ast } }{ \nabla \psi_{ i } }
		\dd{ t }.
	\end{equation*}
	Summarizing these estimates, we have
	\begin{equation*}
		\limsup_{ \varepsilon \to 0 }
			\tilt_excess_{ i }^{ \varepsilon }
			( \nu^{ \ast } ; \eta , u_{ \varepsilon } )
		\leq
		2 \int_{ 0 }^{ T }
			\energy ( u ; \eta )
		\dd{ t }
		+
		2 \int_{ 0 }^{ T }
			\int
				\eta
				\inner*{ \nu^{ \ast } }{ \nabla \psi_{ i } }
		\dd{ t }.
	\end{equation*}
	By focusing on the $ ( i, j )$-th interface, we estimate the energy term by
	\begin{equation*}
		\int_{ 0 }^{ T }
			\energy ( u ; \eta )
		\dd{ t }
		\leq
		\int_{ 0 }^{ T }
			\sigma_{ i , j }
			\int
				\eta
			\abs{ \nabla \chi_{ j } }
		\dd{ t }
		+
		C \sum_{ k \notin \{ i , j \} }
			\int_{ 0 }^{ T }
				\int
					\eta
				\abs{ \nabla \chi_{ k } }
			\dd{ t }
	\end{equation*}
	and the other term via
	\begin{align*}
		\int_{ 0 }^{ T }
			\inner*{ \nu^{ \ast } }
			{
				\int
					\eta
				\nabla \psi_{ i }
			}
		\dd{ t }
		& =
		\sum_{ 1 \leq k \leq P }
			\sigma_{ i , k }
			\int_{ 0 }^{ T }
				\inner*{ \nu^{ \ast } }
				{
					\int
						\eta 
					\nabla \chi_{ k }
				}
			\dd{ t }
		\\
		& \leq
		\int_{ 0 }^{ T }
			\sigma_{ i , j }
			\int
				\eta
				\inner*{ \nu^{ \ast } }{ \nu }
			\abs{ \nabla \chi_{ j } }
		+
		C \sum_{ k \notin \{ i , j \} }
			\int_{ 0 }^{ T }
				\int
					\eta
				\abs{ \nabla \chi_{ k } }
			\dd{ t },
	\end{align*}
	which yields that
	\begin{equation*}
		\limsup_{ \varepsilon \to 0 }
			\tilt_excess_{ i }^{ \varepsilon } ( \nu^{ \ast } ; \eta , u_{ 
			\varepsilon } )
		\leq
		2 \sigma_{ i , j } \int_{ 0 }^{ T }
			\int
				\eta
				\left( 1 + \inner*{ \nu^{ \ast } }{ \nu_{ j } } \right)
			\abs{ \nabla \chi_{ j } }
		\dd{ t }
		+
		C \sum_{ k \notin \{ i , j \} }
			\int_{ 0 }^{ T }
				\int
					\eta 
				\abs{ \nabla \chi_{ k } }
			\dd{ t }.
	\end{equation*}
	Since $ 1 + \inner*{ \nu^{ \ast } }{ \nu_{ j } } = \frac{ 1 }{ 2 } \abs{ 
	\nu^{ \ast } + \nu_{ j } }^{ 2 } $, this finishes the proof.
\end{proof}

Note that we have actually proven a seemingly stronger estimate, since the 
summand $ \abs{ \nu_{ i } - \nu^{ \ast } } $ is not included on the right-hand 
side of the last estimate. However it serves to symmetrize the multiphase 
excess.

Using \Cref{approximate_tilt_excess_estimated_in_limit_by_tilt_excess}, we can 
now prove the convergence of the velocity term.

\begin{proposition}
	\label{convergence_of_velocity_multiphase}
	In the situation of \Cref{initial_convergence_result_multiphase} and under 
	the assumption that the time-integrated energies converge 
	(\ref{energy_convergence}), there exists a finite Radon measure $ \mu $ on 
	$ [ 0 , T ] \times \flattorus $ such that for any $ 1 \leq i , j \leq P $ 
	with $ i \neq j $ and any parameter $ \alpha \in ( 0 , 1 ) $,  any unit 
	vector $ \nu^{ \ast } \in \mathbb{ S }^{ d - 1 } $ and any test vector 
	field $ \xi \in \cont_{ \mathrm{c} }^{ \infty } \left( ( 0 , T ) \times 
	\flattorus ; \mathbb{ R }^{ d } \right) $, we have
	\begin{align*}
		& \limsup_{ \varepsilon \to 0 }
			\abs{
				\int_{ 0 }^{ T }
					\int
						\varepsilon
						\inner*{ \diff u_{ \varepsilon } \xi }
						{ \partial_{ t } u_{ \varepsilon } }
					\dd{ x }
				\dd{ t }
				-
				\sigma_{ i , j }
				\int_{ 0 }^{ T }
					\int_{ \Sigma_{ i , j } }
						\inner*{ \xi }{ \nu_{ i } } V_{ i }
					\dd{ \hm^{ d - 1 } }
				\dd{ t }
			}
		\\
		\lesssim{} &
		\norm{ \xi }_{ \mathrm{sup} }
		\left(
			\frac{ 1 }{ \alpha } \tilt_excess_{ i , j } \left( \nu^{ \ast } ; 
			\rho , u \right) 
			+ \alpha \mu ( \rho ) 
		\right).
	\end{align*}
	Here $ \rho \in \cont^{ \infty } \left( [ 0 , T ] \times \flattorus ;  
	\mathbb{ R }^{ d } 
	\right) $ is any 
	smooth cutoff for the support of $ \xi $.
\end{proposition}

\begin{proof}
	On a technical note, we first pass to a non-relabelled subsequence such 
	that the limes superior becomes the regular limit.
	As in the twophase case, we first choose a majority phase and then freeze 
	the approximate normal $ \varepsilon \nabla u_{ \varepsilon } $ by 
	replacing it with $ - \nabla \phi_{ i } ( u_{ \varepsilon } ) \otimes \nu^{ 
	\ast } $. The error we can be estimated by Young's inequality through
	\begin{align*}
		& \abs{
			\int_{ 0 }^{ T }
				\int
					\varepsilon
					\inner*{ \diff u_{ \varepsilon } \xi }{ \partial_{  t } u_{ 
					\varepsilon } }
				\dd{ x }
			\dd{ t }
			+
			\int_{ 0 }^{ T }
				\int
					\inner*{ \nabla \phi_{ i } ( u_{ \varepsilon } ) \otimes 
					\nu^{ \ast } \xi }{ \partial_{ t } u_{ \varepsilon } }
				\dd{ x }
			\dd{ t }
		}
		\\
		={} &
		\abs{
			\int_{ 0 }^{ T }
				\int
					\sqrt{ \varepsilon }
					\inner*{ 
						\left(
							\sqrt{ \varepsilon } \nabla u_{ \varepsilon }
							+
							\frac{ 1 }{ \sqrt{ \varepsilon } }
							\nabla \phi_{ i } \otimes \nu^{ \ast } 
						\right)
						\xi 
					}
					{ \partial_{ t } u_{ \varepsilon } }
				\dd{ x }
			\dd{ t }
		}
		\\
		\leq{} &
		\frac{ 1 }{ 2 }
		\norm{ \xi }_{ \mathrm{sup} }
		\left(
			\alpha 
			\int_{ 0 }^{ T }
				\int
					\rho \varepsilon 
					\abs{ \partial_{ t } u_{ \varepsilon } }^{ 2 }
				\dd{ x }
			\dd{ t }
			+
			\frac{ 1 }{ \alpha }
			\tilt_excess_{ i }^{ \varepsilon } \left( \nu^{ \ast } ; \rho , 
			u_{ 
			\varepsilon }  \right)
		\right).
	\end{align*}
	We thus have arrived at the term
	\begin{equation*}
		- \int_{ 0 }^{ T }
			\int
				\inner*{ \nabla \phi_{ i } ( u_{ \varepsilon } ) \otimes \nu^{ 
				\ast } \xi }{ \partial_{ t } u_{ \varepsilon } }
			\dd{ x }
		\dd{ t }
		= 
		- \int_{ 0 }^{ T }
			\int
				\partial_{ t } \psi_{ i }^{ \varepsilon }
				\inner*{ \xi }{ \nu^{ \ast } }
			\dd{ x }
		\dd{ t },
	\end{equation*} 
	which by the weak convergence $ \partial_{ t } \psi_{ i }^{ \varepsilon } 
	\rightharpoonup \partial_{ t } \psi_{ i } $ converges to
	\begin{equation*}
		- \sum_{ 1 \leq j \leq P }
			\sigma_{ i , j }
			\int_{ 0 }^{ T }
				\int
					\inner*{ \xi }{ \nu^{ \ast } }
					V_{ j }
				\abs{ \nabla \chi_{ j } }
			\dd{ t }.
	\end{equation*}
	Thus
	\begin{align*}
		& \limsup_{ \varepsilon \to 0 }
			\abs{
				- \int_{ 0 }^{ T }
					\int
						\inner*{ \nabla \phi_{ i } ( u_{ \varepsilon } ) 
						\otimes \nu^{ \ast } \xi }{ \partial_{ t } u_{ 
						\varepsilon } }
					\dd{ x }
				\dd{ t }
				-
				\sigma_{ i j }
				\int_{ 0 }^{ T }
					\int_{ \Sigma_{ i , j } }
						\inner*{ \xi }{ \nu_{ i } }
						V_{ i } 	
					\dd{ \hm^{ d - 1 } }
				\dd{ t }
			}
		\\
		={} &
		\abs{
			\sum_{ 1 \leq k \leq P }
				\sigma_{ i k }
				\int_{ 0 }^{ T }
					\int
						\inner*{ \xi }{ \nu^{ \ast } }
						V_{ k }
					\abs{ \nabla \chi_{ k } }
				\dd{ t }
			+
			\sigma_{ i j }
			\int_{ 0 }^{ T }
				\int_{ \Sigma_{ i , j } }
					\inner*{ \xi }{ \nu_{ i } }
					V_{ i }
				\dd{ \hm^{ d - 1 } }
			\dd{ t }
		}
		\\
		\lesssim{} &
		\norm{ \xi }_{ \mathrm{sup} }
		\sum_{ k \notin \{ i , j \} }
			\int_{ 0 }^{ T }
				\int
					\rho
					\abs{ V_{ k } }
				\abs{ \nabla \chi_{ k } }
			\dd{ t }
		+
		\abs{
			\int_{ 0 }^{ T }
				\int_{ \Sigma_{ i j } }
					\left(
						\inner*{ \xi }{ \nu^{ \ast } }
						+
						\inner*{ \xi }{ \nu_{ i } }
					\right)
					V_{ i }
				\dd{ \hm^{ d -1 } }
			\dd{ t }
		}.
	\end{align*}
	By applying Young's inequality twice and using that on $ \Sigma_{ i , j } 
	$, we have $ V_{ 
	i } = - V_{ j } $, we furthermore estimate via
	\begin{align*}
		& \norm{ \xi }_{ \mathrm{sup} }
		\left(
			\sum_{ k \notin \{ i , j \} }
				\alpha 
				\int_{ 0 }^{ T }
					\int
						\rho
						\abs{ V_{ k } }^{ 2 }
					\abs{ \nabla \chi_{ k } }
				\dd{ t }
				+
				\frac{ 1 }{ \alpha }
				\int_{ 0 }^{ T }
					\int
						\rho
					\abs{ \nabla \chi_{ k } }
				\dd{ t }
			+
			\int_{ 0 }^{ T }
				\int_{ \Sigma_{ i , j } }
					\abs{ V_{ i } }
					\abs{ \nu^{ \ast } - \nu_{ i } }
				\dd{ \hm^{ d - 1 } }
			\dd{ t }
		\right)
		\\
		\leq{} &
		\norm{ \xi }_{\mathrm{sup} }
		\left(
			\alpha
			\sum_{ 1 \leq k \leq P }
				\int_{ 0 }^{ T }
					\int
						\rho
						\abs{ V_{ k } }^{ 2 }
					\abs{ \nabla \chi_{ k } }
				\dd{ t}
			+
			\frac{ 1 }{ \alpha }
			\tilt_excess_{ i j } ( \nu^{ \ast } ; \rho , u )
		\right).
	\end{align*}
	We therefore define the measure $ \mu $ through
	\begin{equation*}
		\mu
		\coloneqq
		\sum_{ 1 \leq k \leq P }
			\abs{ V_{ k } }^{ 2 }
			\abs{ \nabla \chi_{ k } }
			\dd{ t }
		+
		\mu_{ 2 },
	\end{equation*}
	where $ \mu_{ 2 } $ is the weak $ \ast $ limit of some non-relabeled 
	subsequence of the Radon measures $ \varepsilon \abs{ \partial_{ t } u_{ 
	\varepsilon } }^{ 2 } \dd{ x } \dd{ t } $, which stay bounded due to the 
	energy dissipation inequality (\ref{energy_dissipation_sharp}).
	This defines a finite Radon measure on $ [ 0 , T ] \times \flattorus $ by 
	the square-integrability of the velocities observed in 
	\Cref{existence_and_square_integrability_of_velocities_multiphase} and 
	thus, the proof is complete.
\end{proof}

We are now in the position to prove the main result 
\Cref{convergence_to_multiphase_mcf}.

\begin{proof}[Proof of \Cref{convergence_to_multiphase_mcf}.]
	Collecting all previous results (HIER AUSFÜHREN VERMUTLICH; EIN BISSCHEN 
	FAUL SO), we see that the only thing left to show is the full convergence 
	of the velocity term, which states that
	\begin{equation*}
		\lim_{ \varepsilon \to 0 }
			\int_{ 0 }^{ T }
				\int
					\varepsilon
					\inner*{ \diff u_{ \varepsilon } \xi }{ \partial_{ t } u_{ 
					\varepsilon } }
				\dd{ x }
			\dd{ t }
		=
		\sum_{ 1 \leq i < j \leq P }
			\sigma_{ i j }
			\int_{ 0 }^{ T }
				\int_{ \Sigma_{ i , j } }
					\inner*{ \xi }{ \nu_{ i } }
					V_{ i }
				\dd{ \hm^{ d - 1 } }
			\dd{ t }.
	\end{equation*} 
	The key problem we are facing is that the localization estimate 
	\Cref{localization_lemma_with_normals} states that if we can choose the 
	majority phase for a fixed time, then we expect smallness. However we see 
	that the definition of the tilt-excess yields only a time-integrated error. 
	Thus we want to take a partition of unity also in time and control the 
	error.
	
	To this end, let $ 0 = T_{ 0 } < \dotsc < T_{ k } = T $ be a partition of $ 
	[ 0 , T ] $ and for a given $ \delta > 0 $, let $ ( g_{ k } )_{ k = 1 , 
	\dotsc, K } $ be a partition of unity with respect to the intervals 
	$ \left( ( T_{ k - 1 } - \delta , T_{ k } + \delta ) \right) $. As before 
	let $ \eta_{ B } $ be a partition of unity in space with respect to the 
	covering $ \mathcal{ B }_{ r } $. Then for any parameter $ \alpha \in ( 0 , 
	1 ) $, we compute that by \Cref{convergence_of_velocity_multiphase}, we have
	\begin{align*}
		A \coloneqq&
		\limsup_{ \varepsilon \to 0 }
			\abs{
				\int_{ 0 }^{ T }
					\int
						\varepsilon
						\inner*{ \diff u_{ \varepsilon } \xi }{ \partial_{ t } 
						u_{ \varepsilon } }
					\dd{ x }
				\dd{ t }
				-
				\sum_{ 1 \leq i < j \leq P }
					\sigma_{ i j }
					\int_{ 0 }^{ T }
						\int_{ \Sigma_{ i j } }
							\inner*{ \xi }{ \nu_{ i } }
							V_{ i }
						\dd{ \hm^{ d -1 } }
					\dd{ t }
			}
		\\
		\leq{} &
		\sum_{ k = 1 }^{ K }
			\sum_{ B \in \mathcal{ B }_{ r } }
				\limsup_{ \varepsilon \to 0 }
					\abs{
						\int_{ 0 }^{ T }
							\int
								\varepsilon
								g_{ k } \eta_{ B }
								\inner*{ \diff u_{ \varepsilon } \xi }{ 
								\partial_{ t } u_{ \varepsilon } }
							\dd{ x }
						\dd{ t }
						-
						\sum_{ 1 \leq i < j \leq P }
							\sigma_{ i j }
							\int_{ 0 }^{ T }
								\int_{ \Sigma_{ i j } }
									g_{ k } \eta_{ B }
									\inner*{\xi }{ \nu_{ i } }
									V_{ i }
								\dd{ \hm^{ d - 1 } }
							\dd{ t }					
					}
		\\
		\lesssim{} &
		\norm{ \xi }_{ \mathrm{sup} }
		\sum_{ k = 1 }^{ K }
			\sum_{ B \in \mathcal{ B }_{ r } }
				\min_{ i \neq j }
					\min_{ \nu^{ \ast } \in \mathbb{ S }^{ d - 1 } }
						\frac{ 1 }{ \alpha }
						\tilt_excess_{ i , j } ( \nu^{ \ast } ; g_{ k } \rho_{ 
						B } , u )
						+
						\alpha \mu ( g_{ k } \rho_{ B } )
	\end{align*}
	Since no derivative falls on $ g_{ k } $, this term converges as $ \delta $ 
	tends to zero to
	\begin{align}
		\label{error_for _convergence_of_velocity}
		\norm{ \xi }_{ \mathrm{sup} }
		\alpha \mu \left( [ 0 , T ] \times \flattorus \right)
		+
		\norm{ \xi }_{ \mathrm{sup} }
		\frac{ 1 }{ \alpha }
		\sum_{ k = 1 }^{ K }
			\sum_{ B \in \mathcal{ B }_{ r } }
				& \min_{ i \neq j }
					\min_{ \nu^{ \ast } \in \mathbb{ S }^{ d - 1 } }
						\int_{ T_{ k - 1 } }^{ T_{ k } }
							\int
								\rho_{ B } 
								\abs{ \nu_{ i } - \nu^{ \ast } }^{ 2 }
							\abs{ \nabla \chi_{ i } }
							\\
							\notag
							+ &
							\int
								\rho_{ B }
								\abs{ \nu_{ j } + \nu^{ \ast } }^{ 2 }
							\abs{ \nabla \chi_{ j } }
							+ 
							\sum_{ k \notin \{ i , j \} }
								\int
									\rho_{ B }
								\abs{ \nabla \chi_{ k } }
						\dd{ t }.
	\end{align}
	Our problem is now that we would like to take the majority phase 
	approximative inner normal dependent on time, which equates to pulling both 
	minima inside the time integral. If our partition $ \chi $ is smooth, then 
	by choosing partitions $ ( T_{ k } )_{ k = 1 , \dotsc, K } $ whose width 
	goes to zero, this would be possible. Since our partition will in general 
	not be smooth, we instead choose a smooth approximation $ \chi^{ n } $ 
	which converges to $ \chi $ with respect to the strict metric as $ n $ 
	tends to infinity. We estimate 
	that for every $ 1 \leq i \leq P $, every unit vector $ \nu^{ \ast } \in 
	\mathbb{ S }^{ d - 1 } $, fixed index $ k $ and ball $ B $, we have that 
	when replacing $ \chi $ with $ \chi^{ n } $ in  a summand of equation 
	(\ref{error_for 
	_convergence_of_velocity}), we get an error of size at most
	\begin{align*}
		 & \int_{ T_{ k - 1 } }^{ T_{ k } }
		 	\abs{ 
		 		\int
		 			\rho_{ B }
		 			\abs{
		 				\nu_{ i } - \nu^{ \ast }
		 			}^{ 2 }
	 			\abs{ \nabla \chi_{ i } }
	 			-
	 			\int
	 				\rho_{ B }
	 				\abs{ \nu_{ i }^{ n } - \nu^{ \ast } }^{ 2 }
	 			\abs{ \nabla \chi_{ i }^{ n } }
	 		}
 			\\
 			& +
 			\abs{
 				\int
 					\rho_{ B } 
 					\abs{ \nu_{ j } + \nu^{ \ast } }^{ 2 }
 				\abs{ \nabla \chi_{ j } }
 				-
 				\int
 					\rho_{ B }
 					\abs{ \nu_{ j }^{ n } + \nu^{ \ast } }^{ 2 }
 				\abs{ \nabla \chi_{ j }^{ n } }
 			}
 			+
 			\sum_{ l \notin \{ i , j \} }
 				\abs{
 					\int
 						\rho_{ B }
 					\abs{ \nabla \chi_{ l } }
 					-
 					\int
 						\rho_{ B }
 					\abs{ \nabla \chi_{ l }^{ n } }
 				}
 		\dd{ t }
 		\\
 		\lesssim{} &
 		\sum_{ l = 1 }^{ P }
 			\int_{ T_{ k - 1 } }^{ T_{ k } }
 				\abs{ 
 					\int
 						\rho_{ B }
 					\abs{ \nabla \chi_{ l } }
 					-
 					\int
 						\rho_{ B }
 					\abs{ \nabla \chi_{ l }^{ n } }
 				}
 				+
 				\abs{ 
 					\int
 						\rho_{ B }
 						\nu_{ l }
 					\abs{ \nabla \chi_{ l } }
 					- 
 					\int
 						\rho_{ B }
 						\nu_{ l }^{ n }
 					\abs{ \nabla \chi_{ l }^{ n } }
 				}
 			\dd{ t }.
	\end{align*}
	Here $ nu_{ i }^{ n }$ is defined by $ \nabla \chi_{ i }^{ n } / \abs{ 
	\nabla \chi_{ i }^{ n } } $, and for the inequality we used that $ \abs{ 
	\theta - \gamma }^{ 2 } = 2 - \inner*{ \theta }{ \gamma } $ for unit 
	vectors $ \theta $ and $ \gamma $. Thus when replacing $ \chi $ by $ \chi^{ 
	n } $ in (\ref{error_for _convergence_of_velocity}), we get an error of size
	\begin{equation*}
		\frac{ 1 }{ \alpha }
		\sum_{ B \in \mathcal{ B }_{ r } }
			\int_{ 0 }^{ T }
				\sum_{ 1 \leq l \leq P }
					\abs{ 
						\int
							\eta_{ B }
						\abs{ \nabla \chi_{ l } }
						-
						\int
							\eta_{ B }
						\abs{ \nabla \chi_{ l }^{ n } }
					}
					+
					\abs{
						\int
							\eta_{ B }
							\nu_{ l } 
						\abs{ \nabla \chi_{ l } }
						-
						\int
							\eta_{ B }
							\nu_{ l }^{ n }
						\abs{ \nabla \chi_{ l }^{ n } }
					}
			\dd{ t },
	\end{equation*}
	which can be made arbitrarily small independent of the partition of $ [ 0 , 
	T ] $ we have chosen when we let $ n $ tend to infinity.
	Since $ \chi^{ n } $ is smooth, we can now make the width of our partition 
	arbitrarily small and therefore obtain that
	\begin{align*}
		A 
		\lesssim{} &
		\norm{ \xi }_{\mathrm{sup}}
		\alpha \mu \left( [ 0 , T ] \times \flattorus \right)
		\\
		& +
		\norm{ \xi }_{ \mathrm{sup}}
		\frac{ 1 }{ \alpha }
		\int_{ 0 }^{ T }
			\sum_{ B \in \mathcal{ B }_{ r } }
				\min_{ i \neq j }
					\min_{ \nu^{ \ast } \in \mathbb{ S }^{ d - 1 } }
						\int
							\eta_{ B }
							\abs{ \nu_{ i }^{ n } - \nu^{ \ast } }^{ 2 }
						\abs{ \nabla \chi_{ i }^{ n } }
						+
						\int
							\eta_{ B }
							\abs{ \nu_{ j }^{ n } + \nu^{ \ast } }^{ 2 }
						\abs{ \nabla \chi_{ j }^{ n } }
						+
						\sum_{ k \notin \{ i , j \} }
							\int
								\eta_{ B }
							\abs{ \nabla \chi_{ k }^{ n } }
		\dd{ t }.	
	\end{align*}
	Now letting $ n $ tend to infinity yields by the dominated convergence 
	theorem 
\end{proof}
 