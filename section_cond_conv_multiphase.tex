\section{Conditional convergence in the multiphase case}

Let us now turn to the much more interesting and more challenging case where we consider systems of the Allen--Cahn equation (\ref{allen_cahn_eq}), or in other words, we want to consider the case where $ u_{\varepsilon } $ maps to $ \mathbb{ R }^{ N } $ and therefore our potential $ W $ is a map from $ \mathbb{ R }^{ N } $ to $ [ 0 , \infty ) $. The for us most relevant case is when $ W $ has exactly $ P = N + 1 $ zeros given by $ \alpha_{ 1 } , \dotsc, \alpha_{ P } $, but it is no limitation for us to allow more general amount of zeros.

\subsection{Convergence to a moving partition}

One of the many difficulties in the vectorial case is that that there is no easy choice of a primitive for $ \sqrt{ 2 W ( u ) } $ compared to the scalar case. We there saw for example through the Modica-Mortula trick (\ref{modica_mortula_trick}) that this provided a very powerful tool for us, and comparing the composition $ \phi \circ u_{ \varepsilon } $ to $ u_{ \varepsilon } $ was quite simple since the map $ \phi $ was invertible as a consequence of the non-negativity of $ W $.

As a suitable replacement, we shall consider the \emph{geodesic distance} defined as 
\begin{equation*}
		\geodesic_distance ( u, v )
		\coloneqq
		\inf
		\left\{
		\int_{ 0 }^{ 1 }
		\sqrt{ 2 W ( \gamma ) }
		\abs{ \dot{ \gamma }  }
		\dd{t}
		\,
		\colon
		\, \gamma \in \mathrm{ C }^{ 1 } \left( [0, 1 ] ; \mathbb{ R }^{ N } \right) \text{ with } \gamma( 0 ) = u,\, \gamma( 1 )= v 
		\right\}.
\end{equation*}
This indeed defines a metric on $ \mathbb{ R }^{ N } $: If $ \geodesic_distance ( v, w ) = 0 $, then by the continuity of $ W $ and since it only has a discrete set of zeros, we may deduce that $ v = w $. Symmetry can be seen by reversing a given path between two points and the triangle inequality follows from concatenation of two paths and rescaling.
Note moreover that by an approximation argument (for example through splines), we may also take paths $ \gamma $ which are piecewise continuously differentiable which makes constructions of paths easier.

The \emph{geodesic distances} generated by $ W $  are defined as
\begin{equation*}
	\sigma_{ i , j } 
	\coloneqq
	\geodesic_distance ( \alpha_{ i } , \alpha_{ j } )
\end{equation*}
and as a consequence of $ \geodesic_distance $ being a metric satisfy
\begin{equation*}
	\sigma_{ i , k } \leq \sigma_{ i , j } + \sigma_{ j , k },
\end{equation*}
$ \sigma_{ i , j } = 0 $ if and only if $ i $ is equal to $ j $ and $ \sigma_{ i , j } = \sigma_{ j, i } $.

Our replacement for the primitive $ \phi $ is now given for $ 1 \leq i \leq P $ by the function
\begin{equation*}
	\phi_{ i } ( u ) 
	\coloneqq
	\geodesic_distance ( \alpha_{ i } , u ).
\end{equation*}
Our first obstacle is the regularity of the function $ \psi_{ \varepsilon }^{ i } \coloneqq \phi_{ i } \circ u_{ \varepsilon } $. A priori we only know that $ \phi_{ i } $ is locally Lipschitz continuous on $ \mathbb{ R }^{ N } $ and thus differentiable almost everywhere. If $ N = 1 $, then this would already suffice to deduce that $ \psi_{ \varepsilon  }^{ i } $ is weakly differentiable, but in higher dimensions, $ u $ could for example move along a hyperplane where $ \phi_{ i } $ could in theory be nowhere differentiable since it is a Lebesgue nullset. This can however be salvaged through the following chain rule for distributional derivatives by Ambrosio and Maso \cite[Cor.~3.2]{ambrosio_maso_chain_rule}.

\begin{theorem}
	\label{chain_rule_for_distributional_derivatives}
	Let $ \Omega \subseteq \mathbb{ R }^{ d } $ be an open set, $ p \in [0, \infty ] $, $ u \in \wkp^{ 1, p } ( \Omega ; \mathbb{ R }^{ N } ) $ and let $ f \colon \mathbb{ R }^{ N } \to \mathbb{ R }^{ k } $ be a Lipschitz continuous function such that $ f ( 0 ) = 0 $. Then $ v \coloneqq f \circ u \in \wkp^{ 1, p } \left( \Omega , \mathbb{ R }^{ k } \right) $. Furthermore for almost every $ x \in \Omega $ the restriction of $ f $ to the affine space 
	\begin{equation*}
		T_{ x }^{ u }
		\coloneqq
		\left\{
			y \in \mathbb{ R }^{ N }
			\, \colon \,
			y = u ( x ) + \diff u ( x ) z 
			\text{ for }
			z \in \mathbb{ R }^{ d }
		\right\}
		=
		u( x ) 
		+
		\dot{ T }_{ x }^{ u }
	\end{equation*}
	is differentiable at $ u( x ) $ and
	\begin{equation*}
		\diff v 
		=
		\diff \left(
			f |_{ T_{ x }^{ u } }
		\right) ( u ) 
		\diff u 
	\end{equation*}
	holds almost everywhere in $ \Omega $.
\end{theorem}
\begin{remark}
	The matrix 	
	$\diff \left(
	f |_{ T_{ x }^{ u } }
	\right) ( u ) 
	$
	can be interpreted as some matrix in $ \mathbb{ R }^{ k \times n } $ which acts on $ v \in \dot{ T }_{ x }^{ u } $ by
	\begin{equation*}
		\diff \left(
		f |_{ T_{ x }^{ u } }
		\right) ( u ( x ) ) 
		[ v ]
		=
		\lim_{ h \to 0 }
			\frac{ f ( u ( x ) + h v ) - f ( u ( x ) ) }{ h }.
	\end{equation*}
	Thus we may choose a suitable representative since the product $ \diff \left(
	f |_{ T_{ x }^{ u } }
	\right) ( u )  
	\diff u $
	will not change by definition of $ \dot{ T }_{ x }^{ u } $.
	
	Moreover the assumption $ f( 0 ) = 0 $ can be left out on bounded domains by simply subtracting the constant $ f( 0 ) $.
\end{remark}

We are not in the position to prove the following regularity result.

\begin{lemma}
	\label{chain_rule_lemma}
	Let $ u \in \cont \left( [ 0 , T ] ; \lp^{ 2 } ( \flattorus ; \mathbb{ R }^{ N } ) \right) $ with
	\begin{equation*}
		\esssup_{ 0 \leq t \leq T }
			\energy_{ \varepsilon } ( u ) 
		+
		\int_{ 0 }^{ T }
			\int
				\varepsilon 
				\abs{ \partial_{ t } u }^{ 2 }
			\dd{ x }
		\dd{ t }
		< 
		\infty 
	\end{equation*}
	for some $ \varepsilon > 0 $. Then for all $ 1 \leq i \leq P $ there exists a map
	\begin{equation*}
		\partial_{ u } \phi_{ i } ( u )
		\colon
		[ 0 , T ] \times \flattorus
		\to 
		\mathrm{Lin} \left( \mathbb{ R }^{ N } , \mathbb{ R } \right)
	\end{equation*}
	such that the chain rule is valid with the pair $ \partial_{ u } \phi_{ i } ( u ) $ and 
	$ ( \partial_{ t }, \nabla ) u $:
	
	For almost every $ ( t , x ) \in [ 0 , T ] \times \flattorus $ we have
	\begin{equation*}
		\nabla ( \phi_{ i } \circ u )
		=
		\partial_{ u } \phi_{ i } ( u ) \nabla u 
		\quad
		\text{and}
		\quad
		\partial_{ t } ( \phi_{ i } \circ u )
		=
		\partial_{ u } \phi_{ i } ( u ) 
		\partial_{ t } u.
	\end{equation*}
	Furthermore we can control the modulus of $ \partial_{ u } \phi_{ i } ( u ) $ almost everywhere in time and space via the estimate
	\begin{equation}
		\label{estimate_on_partial_u_phi}
		\abs{ \partial_{ u } \phi_{ i } ( u ) }
		\leq
		\sqrt{ 2 W ( u ) }.
	\end{equation}
	Additionally we have $ \phi_{ i } \circ u \in \lp^{ \infty } \left( [ 0 , T ] ; \wkp^{ 1, 1 } ( \flattorus ) \right) \cap \wkp^{ 1, 1 } ( [ 0 , T ] \times \flattorus ) $ with the estimates
	\begin{align}
		\label{l1_estimate_for_phi_composed_u}
		\esssup_{ 0 \leq t \leq T }
			\int
				\abs{ \phi_{ i } \circ u }
			\dd{ x }
		& \lesssim
		1 + \esssup_{ 0 \leq t \leq T } \varepsilon \energy_{ \varepsilon } ( u ) ,
		\\
		\label{l1_estimate_on_nabla_phi_composed_u}
		\esssup_{ 0 \leq t \leq T }
			\int
				\abs{ \nabla ( \phi_{ i } \circ u ) }
			\dd{ x }
		& \leq
		\esssup_{ 0 \leq t \leq T }
			\energy_{ \varepsilon } ( u )
		\shortintertext{and}
		\label{l1_estimate_on_partial_t_phi_composed_u}
		\int_{ 0 }^{ T }
			\int
				\abs{ \partial_{ t } ( \phi_{ i } \circ u ) }
			\dd{ x }
		\dd{ t }
		& \leq
		T
		\esssup_{ 0 \leq t \leq T }
			\energy_{ \varepsilon } ( u )
		+
		\int_{ 0 }^{ T }
			\int
				\varepsilon
				\abs{ \partial_{ t } u }^{ 2 }
			\dd{ x }
		\dd{ t }.
	\end{align}
\end{lemma}

\begin{proof}
	Since \Cref{chain_rule_for_distributional_derivatives} requires Lipschitz continuity of $ \phi_{ i } $, but we only have local Lipschitz continuity, let us first assume that $ u $ is bounded in space and time. Then we may modify $ \phi_{ i } $ outside of a compact set such that it is (globally) Lipschitz continuous and does not change on the image of $ u $.
	
	Since we have via the energy estimate that $ u \in \wkp^{ 1 , 2 } ( [ 0 , T ] \times \flattorus ; \mathbb{ R }^{ N } ) $, we obtain by the distributional chain rule \Cref{chain_rule_for_distributional_derivatives} that $ \psi = \phi_{ i } \circ u \in \wkp^{ 1 , 2 } ( [ 0, T ] \times \flattorus ) $.
	
	Let $ \Pi ( t , x ) $ denote the orthogonal projection of $ \mathbb{ R }^{ N } $ onto $ \dot{ T }_{ x, t }^{ u } $ and define 
	\begin{equation*}
		\partial_{ u } \phi_{ i } ( u ) ( t, x ) [ v ]
		\coloneqq
		\diff ( \phi_{ i } |_{ T_{ t , x }^{ u } } ) ( u ( t , x ) ) [ \Pi ( t , x ) v ].
	\end{equation*}
	This defines a unique row vector and thus we can now proceed to prove inequality (\ref{estimate_on_partial_u_phi}).
	Let $ v \in \dot{ T }_{ t, x }^{ u } $, a real number $ h \in \mathbb{ R } \setminus \{ 0 \} $ and $ \gamma \colon [ 0 , 1 ] \to \mathbb{ R }^{ N } $ be a path connecting $ \alpha_{ i } $ and $ u $. Then we define the new path $ \tilde{ \gamma } \colon [ 0 , 1 ] \to \mathbb{ R }^{ N } $ by 
	\begin{equation*}
		\tilde{ \gamma } ( t ) =
		\begin{cases}
			\gamma ( \frac{ t }{ 2 } ) 
			& , t \leq \frac{ 1 }{ 2 }
			\\
			u + 
			\left( t - \frac{ 1 }{ 2 } \right)
			2 h v
			&, t \geq \frac{ 1 }{ 2 }.
		\end{cases}
	\end{equation*}
	We observe that $ \tilde{ \gamma } $ is a piecewise continuously differentiable path connecting $ \alpha_{i } $ and $ u + h v $, thus we can estimate by a substitution that
	\begin{align*}
		& \geodesic_distance ( \alpha_{ i } , u + hv )
		-
		\int_{ 0 }^{ 1 }
			\sqrt{
				2 W ( \gamma ( t ) ) }
			\abs{ \gamma ' ( t ) }
		\dd{ t }
		\\
		\leq {} &
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( \tilde{ \gamma } ( t ) ) } 
			\abs{ \tilde{ \gamma } ' ( t ) }
		\dd{ t }
		-
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( \gamma ( t ) ) } 
			\abs{ \gamma ' ( t ) }
		\dd{ t }
		\\
		={} &
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( u + t h v ) }
			\abs{ h v }
		\dd{ t }.
	\end{align*}
	Taking the infimum over all $ \cont^{ 1 } $-paths connecting $ \alpha_{ i } $ and $ u $ yields 
	\begin{equation*}
		\geodesic_distance ( \alpha_{ i } , u + h v )
		- 
		\geodesic_distance ( \alpha_{ i } , u )
		\leq
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( u + t h v ) }
			\abs{ h v }
		\dd{ t }.
	\end{equation*}
	Using a similar strategy but with a reversed path, we also obtain the inequality
	\begin{equation*}
		\geodesic_distance ( \alpha_{ i } , u ) 
		-
		\geodesic_distance ( \alpha_{ i } , u + h v )
		\leq
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( u + t h v ) }
			\abs{ h v }
		\dd{ t },
	\end{equation*}
	thus we obtain by the dominated convergence theorem
	\begin{equation*}
		\limsup_{ h \to 0 }
			\abs{
			\frac{ \phi ( u + h v ) - \phi ( u ) }{ h }
			}
		\leq
		\limsup_{ h \to 0 }
			\int_{ 0 }^{ 1 }
				\sqrt{ 2 W ( u + t h v ) }
				\abs{ v }
			\dd{ t }
		= 
		\sqrt{ 2 W ( u ) } \abs{ v },
	\end{equation*}
	which yields
	\begin{equation*}
		\abs{ \diff \phi_{ i } |_{ T_{ t, x }^{ u } } ( u ) [ v ] }
		\leq
		\sqrt{ 2 W ( u ) } \abs{ v }
	\end{equation*}
	and thus gives us the desired inequality (\ref{estimate_on_partial_u_phi}) since $ \abs{ \Pi ( v ) } \leq \abs{ v } $.
	
	Now let us consider the general case and denote by $ u_{ M } $ the truncation of $ u $ defined by
	\begin{equation*}
		u_{ M }^{ j } 
		\coloneqq
		\begin{cases}
			u &, \text{ if} \abs{ u^{ j } } \leq M 
			\\
			M \frac{ u^{ j } }{ \abs{ u_{ j } } }
			&, \text{ else}.
		\end{cases}
	\end{equation*}
	Then we still have $ u_{ M } \in \wkp^{ 1, 2 } ( [ 0 , T ] \times \flattorus ) $ and obtain by the previous step that $ \phi_{ i } \circ u_{ M } \in \wkp^{ 1, 2 } ( [ 0 , T ] \times \flattorus ) $ and that for almost every $ ( t, x ) \in [ 0 , T ] \times \flattorus $, the function $ \phi_{ i } $ is differentiable on $ T_{ t, x }^{ u_{ M } } $. Moreover if $ ( t, x ) \in u^{ - 1 } ( [ - M , M ]^{ N } ) $, then we obtain $ T_{ t, x }^{ u_{ M } } = T_{ t, x }^{ u } $.
	Next we we want to show that $ \phi_{ i } \circ u_{ M } $ converges to $ \phi_{ i } \circ u $ in a suitable sense. First we recognize that $ \phi_{ i } \circ u_{ M } $ converges to $ \phi_{ i } \circ u $ pointwise almost everywhere. Moreover we find a majorant since
	\begin{align}
		\notag
		\phi_{ i } ( v ) 
		&
		\leq
		\int_{ 0 }^{ 1 }
			\sqrt{ 2 W ( \alpha_{ i } + s ( v - \alpha_{ i } ) ) }
			\abs{ v - \alpha_{i } }
		\dd{ s }
		\leq
		\norm{ \sqrt{ 2 W } }_{ \lp^{ \infty } [ v, \alpha_{ i } ] }
		\abs{ v - \alpha_{ i } }
		\\
		\label{majorant_for_phi}
		& \lesssim
		1 + \abs{ v }^{ 1 + p/2 },
	\end{align}
	thus we have $ \phi_{ i } \circ u_{ M } \lesssim 1 + \abs{ u }^{ p } $, which is in integrable majorant. Therefore the dominated convergence theorem yields that $ \phi_{ i } \circ u_{ M } $ converges to $ \phi_{ i } \circ u $ in $ \lp^{ 1 } ( [ 0 , T ] \times \flattorus ) $.
	Moreover estimate (\ref{majorant_for_phi}) together with the $ p $-growth of $ W $ (\ref{polynomial_growth}) already yield the desired $ \lp^{ 1 } $-estimate (\ref{l1_estimate_for_phi_composed_u}).
	
	Furthermore we recognize that on the set $ \{ u_{M } = u \} $, we already have
	\begin{equation*}
		( \partial_{ t } , \nabla ) u_{ M }
		=
		( \partial_{ t } , \nabla ) u
	\end{equation*}
	and the sets $ \{ u_{ M } = u \} $ are non-decreasing, thus
	\begin{equation*}
		\lim_{ M \to \infty }
		\abs{
			\left\{
				u_{ M } \neq u, ( \partial_{ t } , \nabla ) u_{ M } \neq ( \partial_{ t }, \nabla ) u 
			\right\}
		}
		=
		0.
	\end{equation*}
	Moreover we have that for almost every $ ( t, x ) $, the derivative $ \partial_{ u } \phi_{ i } ( u_{ M } ( t , x ) ) $ eventually becomes stationary. We denote its almost everywhere pointwise limit by $ \partial_{ u } \phi_{ i } ( u ) $ and it satisfies almost everywhere
	\begin{equation*}
		\abs{
			\partial_{ u } \phi_{ i } ( u ) 
		}
		\leq
		\sqrt{ 2 W ( u ) }.
	\end{equation*}
	In order to show that $ \phi_{ i } \circ u $ is weakly differentiable with derivative 
	\begin{equation*}
		( \partial_{ t } , \nabla ) \phi_{ i } \circ u
		=
		\partial_{ u } \phi_{ i } ( u ) ( \partial_{ t } u, \nabla u ),
	\end{equation*}
	we compute for a testfunction $ \varphi $ that by the $ \lp^{ 1 } $-convergence, we have
	\begin{align*}
		\int_{ 0 }^{ T }
		\int
			\phi_{ i } \circ u
			( \partial_{ t } , \nabla ) \varphi
		\dd{ x}
		\dd{ t }
		&
		=
		\lim_{ M \to \infty }
			\int_{0 }^{ T }
				\int
					\phi_{ i } \circ u_{ M }
					( \partial_{ t } , \nabla ) u_{ M }
					\varphi
				\dd{ x }
			\dd{ t }
		\\
		& =
		- \lim_{ M \to \infty }
			\int
				\partial_{ u } \phi_{ i } ( u_{ M } )
				( \partial_{ t } , \nabla ) u_{ M }
				\varphi
			\dd{ x }
		\dd{ t }
		\\
		& =
		- \lim_{ M \to \infty }
			\int_{ \abs{ u } \leq M }
				\partial_{ u } \phi_{ i } ( u ) 
				( \partial_{ t } , \nabla ) u
				\varphi
			\dd{ ( t, x ) }
		\\
		& =
		\int_{ 0 }^{ T }
			\int
				\partial_{ u } \phi_{ i } ( u ) 
				( \partial_{ t } , \nabla ) u
				\varphi
			\dd{ x }
		\dd{ t }.
	\end{align*}
	The last inequality is due to the dominated convergence theorem with majorant $ \abs{ \varphi } \sqrt{ 2 W ( u ) } \abs{ ( \partial_{ t } , \nabla ) u } $.
	It remains to prove the estimates (\ref{l1_estimate_on_nabla_phi_composed_u}) and (\ref{l1_estimate_on_partial_t_phi_composed_u}). These follow from applications of Young's inequality
	\begin{align*}
		\esssup_{ 0 \leq t \leq T }
			\int
				\abs{ \nabla ( \phi_{ i } \circ u ) }
		& =
		\esssup_{ 0 \leq t \leq T }
			\int
				\abs{ \partial_{ u } \phi_{ i } ( u ) \nabla u }
			\dd{ x }
		\\
		& \leq
		\esssup_{ 0 \leq t \leq T }
			\int
				\sqrt{ 2 W ( u ) }
				\abs{ \nabla u }
			\dd{ x }
		\\
		& \leq
		\sup_{ 0 \leq t \leq T }
			\energy_{ \varepsilon } ( u_{ \varepsilon } )
		\shortintertext{and}
		\int_{ 0 }^{ T }
			\int
				\abs{ \partial_{ t } ( \phi_{ i } \circ u ) }
			\dd{ x }
		\dd{ t }
		& \leq
		\int_{ 0 }^{ T }
			\int
				\frac{ 1 }{ \sqrt{ \varepsilon } }
				\sqrt{ 2 W ( u ) }
				\sqrt{ \varepsilon }
				\abs{ \partial_{ t } u }
			\dd{ x }
		\dd{ t }
		\\
		& \leq
		\int_{ 0 }^{ T }
			\int
				\frac{ 1 }{ \varepsilon}
				W ( u_{ \varepsilon } )
				+
				\frac{\varepsilon}{ 2 }
				\abs{ \partial_{  t } u }^{ 2 }
			\dd{ x }
		\dd{ t },
	\end{align*}
	which finishes our proof.
\end{proof}

With this powerful tool on our hands, we are in the position to prove a similar result to \Cref{initial_convergence_result} for the multiphase case.

\begin{proposition}
	\label{initial_convergence_result_multiphase}
	Given initial data $ u_{ \varepsilon }^{ 0 } = \sum_{ i = 1 }^{ P } \chi_{ i }^{ 0 } \alpha_{ i } $ whose energies satisfy
	\begin{equation*}
		\energy_{ \varepsilon } ( u_{ \varepsilon }^{ 0 } ) 
		\to 
		\energy ( u^{ 0 } ) 
		\eqqcolon
		E_{ 0 }
		< 
		\infty,
	\end{equation*}
	there exists for any sequence $ \varepsilon $ some non-relabelled subsequence such that the solutions of the Allen--Cahn equation (\ref{allen_cahn_eq}) with initial condition $ u_{ \varepsilon }^{ 0 } $ converge in $ \lp^{ 1 } \left( ( 0 , T ) \times \flattorus ; \mathbb{ R }^{ N } \right) $ to some $ u = \sum_{ i = 1 }^{ P } \chi_{ i } \alpha_{ i } $ with a partition $ \chi \in \bv \left( ( 0 , T ) \times \flattorus ; \{ 0 , 1 \}^{ P } \right) $.
	Furthermore we have
	\begin{equation}
		\label{energy_estimate_for_limit_u}
		\esssup_{ 0 \leq t \leq T }
			\energy ( u ) 
		\leq
		\energy_{ 0 }
	\end{equation}
	and for all $ 1 \leq i \leq P $ the compositions $ \phi_{ i } \circ u_{ \varepsilon } $ are uniformly bounded in $ \bv ( ( 0 , T ) \times \flattorus ) $ and converge to $ \phi_{ i } \circ u $ in $ \lp^{ 1 } ( ( 0 , T ) \times \flattorus $. 
\end{proposition}

\begin{remark}
	The proof is quite similar to the proof of \Cref{initial_convergence_result}, but we have to work more in order to obtain the desired convergence to $ u $.
\end{remark}

\begin{proof}
	By \Cref{existence_of_ac_solution} the solution $ u_{ \varepsilon } $ of (\ref{allen_cahn_eq}) satisfies the assumptions of \Cref{chain_rule_lemma}.
	Thus $ \psi_{ i }^{ \varepsilon } \coloneqq \varphi_{ i } \circ u_{ \varepsilon } $ is uniformly bounded in $ \bv \left( ( 0 , T ) \times \flattorus \right) $ as $ \varepsilon $ tends to zero for all $ 1 \leq i \leq P $ and thus we find a non-relabelled subsequence and $ v_{ i } \in \bv \left( ( 0 , T ) \times \flattorus \right) $ such that $ \psi_{ i }^{ \varepsilon } $ converges to $ v_{ i } $ in $ \lp^{ 1 } \left( ( 0 , T ) \times \flattorus \right) $ and pointwise almost everywhere. 
	
	We now want to show that we can write $ v_{ i } = \phi_{ i } \circ u $ for $ u = \sum \chi_{ j } \alpha_{ j } $. An elegant proof of this presented in \cite[Thm.~4.1]{fonseca_tartar_1989} can be done through the fundamental theorem of Young measures (\cite[Thm.~3.1]{Müller1999}). By passing to another non-relabelled subsequence of $ u_{ \varepsilon } $, we obtain that $ u_{ \varepsilon } $ generates a Young measure $ \nu $. Since $ u $ is $ \lp^{ p } $-bounded, we have that for almost every $ (t, x ) $, the measure $ \nu_{ ( t, x ) } $ is a probability measure. Moreover the sequence $ W ( u_{ \varepsilon } ) $ is uniformly integrable since 
	\begin{equation*}
	 	0 \leq W ( u_{ \varepsilon } ) \leq \frac{ 1 }{ \varepsilon } W ( u_{ \varepsilon } ) \to 0 
	 \end{equation*}
 	in $ \lp^{ 1 } $. Thus we obtain that for all $ \varphi \in \lp^{ \infty } ( [ 0 , T ] \times \flattorus ) $
 	\begin{equation*}
 		0
 		=
 		\lim_{ \varepsilon \to 0 }
 			\int_{ 0 }^{ T }
 				\int
 					\varphi (t, x )
 					W ( u_{ \varepsilon } (t, x ) )
 				\dd{ x }
 			\dd{ t }
 		=
 		\int_{ 0 }^{ T }
 			\int
 				\varphi ( t, x ) 
				\int_{ \mathbb{ R }^{ N } }
					W ( y )
				\dd{ \nu_{ ( t, x ) } ( y ) }
 			\dd{ x }
 		\dd{ t },
 	\end{equation*}
 	which implies that for almost every $ ( t, x ) $, the probability measure $ \nu_{ ( t, x ) } $ is supported on the set $ \{ \alpha_{ 1 } , \dotsc, \alpha_{ P } \} $. Therefore we can write
 	$ \nu_{ ( t , x ) } = \sum_{ j = 1 }^{ P } \lambda_{ j } \delta_{ \alpha_{ j } } $ for non-negative numbers $ \lambda_{ j } \in [0 ,1 ] $ with $ \sum \lambda_{ j } = 1 $.
 	
 	Now let $ 1 \leq i \leq P $. For every $ f \in \cont_{ 0 } ( \mathbb{ R } ) $, we have that $ f \circ \phi_{ i } \in \cont_{ 0 } ( \mathbb{ R }^{ N } ) $, and thus we can compute that $ \phi_{ i } \circ u_{ \varepsilon } $ generates the Young measure given at almost every point $ ( t, x ) $ by $ \nu_{ ( t , x ) } = \sum \lambda_{ j } \delta_{ \phi_{ i } ( \alpha_{ j } ) } $.
 	But $ \phi_{ i } \circ u_{ \varepsilon } $ converges to $ v_{ i } $ in $ \lp^{ 1 } $, thus especially in measure, which implies by \cite[Cor.~3.2]{Müller1999} that our convex combination already has to be trivial, or in other words, we can write 
 	\begin{equation*}
 		\nu_{ ( t , x ) }
 		=
 		\sum_{ j= 1 }^{ P }
 			\mathds{ 1 }_{ \Omega_{ j } ( t ) } ( x )
 			\delta_{ \alpha_{ j } }
 	\end{equation*}
 	for a time-dependent partition $ ( \Omega_{ j } ( t ) )_{ j = 1 , \dotsc , P } $ of $ \flattorus $. Thus we can write 
 	\begin{equation*}
 		\delta_{ v_{ i } ( t , x ) }
 		=
 		\sum_{ j = 1 }^{ P }
 			\mathds{ 1 }_{ \Omega_{ j } ( t ) } ( x )
 			\delta_{ \phi_{ i } ( \alpha_{ j } ) },
 	\end{equation*}
 	and by defining 
 	$ u \coloneqq \sum_{ j = 1 }^{ P } \mathds{ 1 }_{ \Omega_{ j } ( t ) } ( x ) \alpha_{ j } $, 
 	we obtain that 
 	\begin{equation*} 
 		v_{ i } = 
 		\phi_{ i } \circ u  = \sum_{ j = 1 }^{ P } \mathds{ 1 }_{ \Omega_{ j } ( t ) } ( x ) \sigma_{ i , j } .
 	\end{equation*}
 
 	What is left to show is the energy estimate (\ref{energy_estimate_for_limit_u}) and that partition function $ \chi ( t , x ) \coloneqq \left( \mathds{ 1 }_{ \Omega_{ 1 } ( t )  } ( x ) , \dotsc, \mathds{ 1 }_{ \Omega_{ P } ( t ) } ( x ) \right) $ is of bounded variation.
 	The latter follows from the Fleming--Rishel co-area formula \cite{Fleming_Rishel_coarea_formula} which yields since $ \phi_{ i } \circ u \in \bv \left( ( 0 , T ) \times \flattorus \right) $ that
 	\begin{align*}
 		\infty
 		& >
 		\abs{ 
 			( \partial_{ t } , \nabla )
 			\phi_{ i } \circ u
 		}
 		\left( ( 0 , T ) \times \flattorus \right)
 		\\
 		&
 		=
 		\int_{ 0 }^{ \infty }
 			\hm^{ d } \left(
 				\partial_{ \ast } \left(
 					\left\{
 						( t, x ) 
 						\, \colon \,
 						\phi_{ i } ( u ( t , x ) ) \leq s 
 					\right\}
 				 \right)
 			\right)
 		\dd{ s }
 		\\
 		&
 		\geq
 		\int_{ 0 }^{ \min_{ i \neq j } \sigma_{ i , j } }
 			\hm^{ d } \left(
 				\partial_{ \ast }
 				\left\{
 					( t , x ) \in ( 0 , T ) \times \flattorus 
 					\, \colon \,
 					\chi_{ i } ( t , x ) = 1
 				\right\}
 			\right)
 		\dd{ s }
 		\\
 		&=
 		\min_{ i \neq j }
 			\sigma_{ i , j }
 		\abs{
 			( \partial_{ t } , \nabla ) \chi_{ i }
 		}
 		\left(
 			( 0 , T ) \times \flattorus
 		\right).
 	\end{align*}
 	Here we denote by $ \partial_{ \ast } A $ the measure theoretic boundary of a given measurable set $ A $, as defined for example in \cite[Def.~5.7]{evans_gariepy_measure_theory_and_fine_props}.
 	Since we have $ \sigma_{ i , j } > 0 $ for $ i \neq j $, this proves that $ \chi_{ i } \in \bv \left( ( 0, T ) \times \flattorus \right) $.
 	
 	The energy estimate is a non-trivial consequence of the lower semicontinuity of the variation measure and has been proven by Baldo in \cite{baldo_minimal_interface_criterion}. We will recap the proof since it provides some insight into the geometry of the phases.
\end{proof}

\begin{definition}
	Given a partition $ \left( \Omega_{ i } \right)_{ i = 1 , \dotsc , P } $ of the flat torus $ \flattorus $, where all sets $ \Omega_{ i } $ are of finite perimeter, we define the $ (i,j)$-th interface as $ \Sigma_{ i , j } \coloneqq \partial_{ \ast } \Omega_{ i } \cap \partial_{ \ast } \Omega_{ j } $.
\end{definition}

We already mentioned that we want to apply the lower semicontinuity of the variation measure. Since we can think of $ \phi_{ i } $ as being locally the correct choice for suitable $ i $, we introduce the following notion.

\begin{definition}
	Let $ \mu , \nu $ be regular positive Borel measures on $ \flattorus $. Define the supremum $ \mu \vee \nu $ of $ \mu $ and $ \nu $ as the smallest regular positive measure which is greater or equal to $ \mu $ and $ \nu $ on a Borel subset of $ \flattorus $. By the regularity, we have
	\begin{equation*}
		\mu \vee \nu ( U ) 
		=
		\sup \left\{
			\mu ( V ) + \mu ( W )
			\, \colon \,
			V \cap W = \emptyset,
			V \cup W \subseteq U, 
			V \text{ and } W \text{ are open subsets of } \flattorus
		\right\}
	\end{equation*}
	for any open subset $ U \subseteq \flattorus $.
\end{definition}

It is natural to ask how we can characterize the total variation of $ \psi_{ i } = \phi_{ i } \circ u = \sum \mathds{ 1 }_{ \Omega_{ j } } \sigma_{ i , j } $. For this we note that when going from set $ \Omega_{ j } $ to $ \Omega_{ k } $, our function jumps from $ \sigma_{ i , j } $ to $ \sigma_{ i , k } $. Thus we obtain the following intuitive result.

\begin{lemma}
	\label{rewriting_variation_of_psi_i}
	In the setting of \Cref{initial_convergence_result_multiphase} we can write
	\begin{equation*}
		\abs{ \nabla \psi_{ i } }
		=
		\sum_{ 1 \leq j < k \leq P }
			\abs{ \sigma_{ i , j } - \sigma_{ i , k } }
			\dd{ \hm^{ d - 1 } |_{ \Sigma_{ j , k } } }.
	\end{equation*}
\end{lemma}

The proof can be found in the Appendix. If we now consider the supremum of the measures $ \left( \abs{ \nabla \psi_{ i } } \right)_{ i = 1 , \dotsc, P } $, we notice that all of them are supported on the interfaces $ \Sigma_{ j , k } $, and that by the triangle inequality for the surface tensions, we have 
\begin{equation}
	\label{maximum_of_differences_of_surface_tensions}
	\max_{ 1 \leq i \leq P }
		\abs{ \sigma_{ i , j } - \sigma_{ i , k } }
	=
	\sigma_{ j , k }.
\end{equation}
Thus, we obtain the following.

\begin{proposition}
	In the situation of \Cref{initial_convergence_result_multiphase} , we have
	\begin{equation*}
		\left(
			\bigvee_{ i = 1 }^{ P }
			\abs{ \nabla \psi_{ i } }
		\right)
		=
		\sum_{ 1 \leq i < j \leq P }
		 \sigma_{ i , j }
		 \dd{ \hm^{ d - 1 } |_{ \Sigma_{ i , j } } }.
	\end{equation*}
\end{proposition}

\begin{proof}
	This follows by combining \Cref{rewriting_variation_of_psi_i} and \Cref{supremum_of_measures_lemma} with the above equation (\ref{maximum_of_differences_of_surface_tensions}).
\end{proof}

Collecting our observations, we can finish our arguments.

\begin{proof}[Continuation of the proof for \Cref{initial_convergence_result_multiphase}]
	We are left with proving the estimate (\ref{energy_estimate_for_limit_u}). We first note that as for the proof of (\ref{l1_estimate_on_nabla_phi_composed_u}), it holds that for any open subset $ U $ of the flat torus, we have for almost every time $ t $ the estimate
	\begin{equation*}
		\liminf_{ \varepsilon \to 0 } 
			\int_{ U }
				\frac{ 1 }{ \varepsilon }
				W ( u_{ \varepsilon } ( t )  )
				+
				\frac{ \varepsilon }{ 2 }
				\abs{ \nabla u_{ \varepsilon } ( t ) }^{ 2 }
			\dd{ x }
		\geq
		\abs{ \nabla \psi_{ i } ( t ) } ( U ).
	\end{equation*}
	Since
	\begin{equation*}
		\left(
		\bigvee_{ i = 1 }^{ P }
			\abs{ \nabla \psi_{ i } } 
		\right) 
		( \flattorus )
		=
		\sup \left\{
			\sum_{ i = 1 }^{ P }
				\abs{ \nabla \psi_{ i } } ( U_{ i } )
			\, \colon \,
			( U_{ i } )_{ i } \text{ are disjoint open subsets of } \flattorus
		\right\},
	\end{equation*}
	we finally deduce
	\begin{align*}
		\esssup_{ 0 \leq t \leq T }
			\energy ( u ( t ) )
		& =
		\esssup_{ 0 \leq t \leq T }
			\sum_{ 1 \leq i < j \leq P }
				\sigma_{ i , j }
				\hm^{ d - 1 } ( \Sigma_{ i , j } ( t ) )
		\\
		& = \esssup_{ 0 \leq t \leq T }
		\left(
			\bigvee_{ i = 1 }^{ P }
				\abs{ \nabla \psi_{ i } ( t ) }
		\right) ( \flattorus )
		\\
		& \leq
		\esssup_{ 0 \leq t \leq T }
			\liminf_{ \varepsilon \to 0 }
				\energy_{ \varepsilon } ( u_{ \varepsilon } ( t ) )
		\\
		& \leq
		\energy_{ 0 }.
	\end{align*}
	The last inequality is due the energy dissipation inequality (\ref{energy_dissipation_sharp}).
\end{proof}

Nextup, we want to prove a stronger convergence of $ u_{ \varepsilon } $ to $ u $. This will let us prove that $ u $ achieves to initial data (and the existence of normal velocities?).

\begin{lemma}
	In the situation of \Cref{initial_convergence_result_multiphase} we have 
	$ \psi_{ i }^{ \varepsilon } \in \wkp^{ 1 , 2 } \left(
		[ 0 , T ] ; \lp^{ 1 } ( \flattorus )
	\right)
	$
	with the corresponding estimate
	\begin{equation}
		\label{l2_estimate_on_partial_t_psi_i}
		\left(
			\int_{ 0 }^{ T }
				\left(
					\int
						\abs{ \partial_{ t } \psi_{ i }^{ \varepsilon } }
					\dd{ x }
				\right)^{ 2 }
			\dd{ t }
		\right)^{ 1/2 }
		\lesssim
		\energy_{ \varepsilon } ( u_{ \varepsilon } ( 0 ) ).
	\end{equation}
	Furthermore the sequence $ u_{ \varepsilon } $ is precompact in 
	$ \cont \left(
		[ 0 , T ] ; \lp^{ 2 } ( \flattorus ; \mathbb{ R }^{ N } )
	\right) $.
	In particular we get that $ u $ achieves the initial data in 
	$ \cont \left( [ 0 , T ] ; \lp^{ 2 } ( \flattorus ; \mathbb{ R }^{ N } )
	\right) $.
\end{lemma}

\begin{remark}
	This statement is almost similar to its twophase equivalent \Cref{l2_bound_on_psi_varepsilon} and the proof uses a similar strategy.
\end{remark}

\begin{proof}
	\begin{description}[wide=0pt]
		\item[Step 1:] Estimate (\ref{l2_estimate_on_partial_t_psi_i}) holds
		
		We compute that by Hölder's inequality and the energy dissipation inequality (\ref{energy_dissipation_sharp})
		\begin{align*}
			\int_{ 0 }^{ T }
				\left(
					\int
						\abs{ \partial_{ t } \psi_{ i }^{ \varepsilon } }
					\dd{ x }
				\right)^{ 2 }
			\dd{ t }
			& \leq
			\int_{ 0 }^{ T }
				\left(
					\int
						\sqrt{ 2 W ( u_{ \varepsilon } ) }
						\abs{ \partial_{ t } u_{ \varepsilon } }
					\dd{ x }
				\right)^{ 2 }
			\dd{ t }
			\\
			& =
			\int_{ 0 }^{ T }
				\int
					\frac{ 2 }{ \varepsilon }
					W ( u_{ \varepsilon } )
				\dd{ x }
				\int
					\varepsilon 
					\abs{ \partial_{ t } u_{ \varepsilon } }^{ 2 }
				\dd{ x }
			\dd{ t }
			\\
			& \leq
			2 \energy_{ \varepsilon } ( u_{ \varepsilon } ( 0 ) )
			\int_{ 0 }^{ T }
				\int
					\varepsilon 
					\abs{ \partial_{ t } u_{ \varepsilon } }^{ 2 }
				\dd{ x }
			\dd{ t }
			\\
			& \leq
			2 \energy_{ \varepsilon } ( u_{ \varepsilon } ( 0 ) )^{ 2 }.
		\end{align*}
		By estimate (\ref{l1_estimate_on_nabla_phi_composed_u}), we especially obtain $ \psi_{ i }^{ \varepsilon } \in \lp^{ 2 } \left( [ 0 , T ] ; \lp^{ 1 } ( \flattorus ) \right) $.
		
		\item[Step 2:] The sequence $ \psi_{ i }^{ \varepsilon } $ is precompact in $ \cont \left( [ 0 , T ] ; \lp^{ 1 } ( \flattorus ) \right) $.
		
		This follows exactly as in the twophase case from the embedding of 
		$ \wkp^{ 1 , 2 } \left( [ 0 , T ] ; \lp^{ 1 } ( \flattorus ) \right) $
		into $ \cont^{ 1/2 } \left( [ 0 , T ] ; \lp^{ 1 } ( \flattorus ) \right) $.
		
		\item[Step 3:] The sequence $ u_{ \varepsilon } $ converges to $ \sum_{ i } \chi_{ i } \mathds{ 1 }_{ \Omega_{ i } } \alpha_{ i } $ in measure uniformly in time.
		
		Let $ \rho > 0 $. Then by definition of $ \phi_{ i } $, there exists some $ \delta > 0 $ such that if  
		$ \abs{ v - \alpha_{ i } } > \rho $ holds for all $ 1 \leq i \leq P $, then we already have $ \phi_{ v } > \delta $ for all $ 1 \leq i \leq P $.
		Therefore we can estimate
		\begin{align*}
			\esssup_{ 0 \leq t \leq T }
				\lm^{ d } \left(
					\left\{
						x 
						\, \colon \,
						\abs{ u_{ \varepsilon } - \sum_{ i } \mathds{ 1 }_{ \Omega_{ i } \alpha_{ i } } } > \rho 
					\right\}
				\right)
			& = 
			\esssup_{ 0 \leq t \leq T }
				\sum_{ i = 1 }^{ P }
					\lm^{ d }
						\left(
							\left\{
								x \in \Omega_{ i }
								\, \colon \,
								\abs{ u_{ \varepsilon } - \alpha_{ i } }
								> \rho
							\right\}	
						\right)
			\\
			& \leq
				\esssup_{ 0 \leq t \leq T }
					\sum_{ i = 1 }^{ P }
						\lm^{ d } \left(
							\left\{
								x \in \Omega_{ i }
								\, \colon \,
								\phi_{ i } ( u_{ \varepsilon } ) > \delta 
							\right\}
						\right)
			\\
			& \leq
			\esssup_{ 0 \leq t \leq T }
				\frac{ 1 }{ \delta }
				\sum_{ i = 1 }^{ P }
					\int_{ \Omega_{ i } }
						\abs{ \psi_{ i }^{ \varepsilon } }
					\dd{ x }
			\\
			& \leq
			\esssup_{ 0 \leq t \leq T }
				\frac{ 1 }{ \delta }
				\sum_{ i = 1 }^{ P }
					\int
						\abs{ \psi_{ i }^{ \varepsilon } - \psi_{ i } }
					\dd{ x },
		\end{align*}
		which converges to $ 0 $ by Step 2.
		
		\item[Step 4:] The sequence $ u_{ \varepsilon }^{ 2 } $ is equiintegrable uniformly in time
		
		This follows as in the twophase case as well.
		
		\item[Step 5:] The sequence $ u_{ \varepsilon } $ converges in $ \cont \left( [ 0 , T ] ; \lp^{ 2 } ( \flattorus ; \mathbb{ R }^{ N } ) \right) $.
		
		Here the proof does not change as well.
	\end{description}
\end{proof}


 